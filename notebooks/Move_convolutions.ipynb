{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the symmetry-corrected indices for move-based convolution\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the coefficient generation logic the naive way\n",
    "cell = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[ 0.  0.  6.  0.]\n",
      " [ 0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  2.]\n",
      " [ 0.  7.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# display-only code, to visually check the coeffs are in the correct locations on the board\n",
    "from neural.neural_ import to_pair, generate_all_moves_by_index, move_convolution_indices\n",
    "from constants import BOARD_SIZE, BOARD_WIDTH, NUM_BIASES\n",
    "from math import floor\n",
    "\n",
    "all_inds, num_coeffs = move_convolution_indices()\n",
    "\n",
    "\n",
    "num_coeffs -= NUM_BIASES # the first 10 in the above function are biases, don't need them\n",
    "num_fields = BOARD_SIZE\n",
    "\n",
    "cell = cell+1\n",
    "tmp = all_inds[cell]\n",
    "a = np.zeros([BOARD_WIDTH,BOARD_WIDTH])\n",
    "for (ind, coeff) in tmp[1:]:\n",
    "    pair = to_pair(ind)\n",
    "    a[pair[0],pair[1]] = coeff - NUM_BIASES + 1\n",
    "\n",
    "print(to_pair(cell))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2]\n",
      "[[[ 0.16027431  0.        ]\n",
      "  [-0.29731864 -0.        ]\n",
      "  [-0.46966732 -0.        ]]\n",
      "\n",
      " [[ 0.65186518  1.36244631]\n",
      "  [-0.02570902 -0.05224879]\n",
      "  [ 0.03826804  1.73317242]]]\n"
     ]
    }
   ],
   "source": [
    "# try calling conv_stack directly from Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from neural.tensorflow_utils import conv_stack\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    in_fields_np = np.ones([2,num_fields])\n",
    "    in_fields_np[0,3] = 0\n",
    "    in_fields_np[0,5] = 0\n",
    "    my_pos = np.array([12, 12])\n",
    "    other_pos =  np.array([5,5])\n",
    "    inputs_np = np.concatenate([in_fields_np, my_pos[:,None], other_pos[:,None]],\n",
    "                              1)\n",
    "    #print(inputs_np.shape)\n",
    "    inputs =tf.constant(inputs_np)# tf.placeholder(shape =[None, num_fields+2], dtype = tf.float32) #\n",
    "    #print(sess.run(inputs))\n",
    "    out = conv_stack(inputs, 5,sess)\n",
    "    \n",
    "    dummy = np.array([50,50])[:,None]\n",
    "    #print(sess.run(get_random_index(inputs, tf.constant(dummy))))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    stack_result = sess.run(out)#, feed_dict={inputs:inputs_np})\n",
    "    print(stack_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "# load game simulation data\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "from neural.data_utils import load_simulation_data\n",
    "\n",
    "fn = '../data/states.pickle'\n",
    "if True:\n",
    "# try:\n",
    "#     with open(fn, 'rb') as f:\n",
    "#         states = pickle.load(f)\n",
    "# except:\n",
    "    files = glob.glob('../data/4x4tiny.pickle')\n",
    "    #files = glob.glob('../data/epsgreedy/*')\n",
    "    #files = glob.glob('../data/ID_x2_1000ms/result_ID*.pickle')\n",
    "    #print(files)\n",
    "    depths =load_simulation_data(files)\n",
    "    keys = list(depths.keys())\n",
    "    #print(keys)\n",
    "    games = depths[keys[0]]\n",
    "    #print(games[0])\n",
    "    states = [state for game in games for state in game if 'score' in state] \n",
    "    print(len(states))\n",
    "    with open(fn, 'wb') as f:\n",
    "        pickle.dump(states,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1271, 16, 1) (1271, 16, 2) (1271, 1)\n"
     ]
    }
   ],
   "source": [
    "from neural.data_utils import prepare_data_for_model\n",
    "board_full, player_pos, y = prepare_data_for_model(states,'simple_score')\n",
    "print(board_full.shape, player_pos.shape, y.shape)\n",
    "y[y ==float('-inf')] = 0\n",
    "y[y ==float('inf')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 16, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 16, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 16, 3)         0           input_2[0][0]                    \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_1 (ConvByMove (None, 16, 8)         240         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 16, 8)         32          conv_by_move_layer_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 8)         0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_2 (ConvByMove (None, 16, 8)         600         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 16, 8)         32          conv_by_move_layer_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 16, 8)         0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_3 (ConvByMove (None, 16, 8)         600         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 16, 8)         0           conv_by_move_layer_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 16, 8)         0           conv_by_move_layer_1[0][0]       \n",
      "                                                                   dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 16, 8)         32          add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 16, 8)         0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_4 (ConvByMove (None, 16, 8)         600         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 16, 8)         32          conv_by_move_layer_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 16, 8)         0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_5 (ConvByMove (None, 16, 8)         600         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 16, 8)         0           conv_by_move_layer_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 16, 8)         0           add_1[0][0]                      \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 16, 8)         32          add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 16, 8)         0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_6 (ConvByMove (None, 16, 8)         600         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 16, 8)         32          conv_by_move_layer_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 16, 8)         0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_7 (ConvByMove (None, 16, 8)         600         activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 16, 8)         0           conv_by_move_layer_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 16, 8)         0           add_2[0][0]                      \n",
      "                                                                   dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 16, 8)         32          add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 16, 8)         0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_8 (ConvByMove (None, 16, 8)         600         activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 16, 8)         32          conv_by_move_layer_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 16, 8)         0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_9 (ConvByMove (None, 16, 8)         600         activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 16, 8)         0           conv_by_move_layer_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 16, 8)         0           add_3[0][0]                      \n",
      "                                                                   dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 16, 8)         0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 16, 10)        0           activation_9[0][0]               \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 160)           0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            1610        flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             11          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6,917\n",
      "Trainable params: 6,789\n",
      "Non-trainable params: 128\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fit the naive score as a first test of our network\n",
    "from neural.keras_utils import deep_model_fun\n",
    "model = deep_model_fun(num_features = 8, num_res_modules = 4, drop_rate = 0.01, activation = 'linear')\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam',  loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1271/1271 [==============================] - 6s - loss: 9.9684      \n",
      "Epoch 2/30\n",
      "1271/1271 [==============================] - 3s - loss: 4.3643     \n",
      "Epoch 3/30\n",
      "1271/1271 [==============================] - 3s - loss: 3.4885     \n",
      "Epoch 4/30\n",
      "1271/1271 [==============================] - 3s - loss: 3.0461     \n",
      "Epoch 5/30\n",
      "1271/1271 [==============================] - 3s - loss: 2.8112     \n",
      "Epoch 6/30\n",
      "1271/1271 [==============================] - 3s - loss: 2.2658     \n",
      "Epoch 7/30\n",
      "1271/1271 [==============================] - 3s - loss: 2.0466     \n",
      "Epoch 8/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.6279     \n",
      "Epoch 9/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.5493     \n",
      "Epoch 10/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.5620     \n",
      "Epoch 11/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.1928     \n",
      "Epoch 12/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.1318     \n",
      "Epoch 13/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.1570     \n",
      "Epoch 14/30\n",
      "1271/1271 [==============================] - 4s - loss: 1.0577     \n",
      "Epoch 15/30\n",
      "1271/1271 [==============================] - 3s - loss: 1.0099     \n",
      "Epoch 16/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.8969     \n",
      "Epoch 17/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.9711     \n",
      "Epoch 18/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.9072     \n",
      "Epoch 19/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.8043     \n",
      "Epoch 20/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.8172     \n",
      "Epoch 21/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6904     \n",
      "Epoch 22/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6778     \n",
      "Epoch 23/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6347     \n",
      "Epoch 24/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.7297     \n",
      "Epoch 25/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.7348     \n",
      "Epoch 26/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6618     \n",
      "Epoch 27/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6350     \n",
      "Epoch 28/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6790     \n",
      "Epoch 29/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.6847     \n",
      "Epoch 30/30\n",
      "1271/1271 [==============================] - 3s - loss: 0.5433     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc87ce7ac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [player_pos, board_full],y = y, batch_size = 16, epochs=30, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G': 0.96059601,\n",
       " 'active_player': None,\n",
       " 'allscores': None,\n",
       " 'depth': 11,\n",
       " 'game': array([ 1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.]),\n",
       " 'game_': None,\n",
       " 'move': (0, 1),\n",
       " 'pos': (2, 5),\n",
       " 'score': inf,\n",
       " 'simple_score': -8.0,\n",
       " 'winner': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test = [s for s,state in enumerate(states) if 'score' not in state ]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "# Now let's get all those games where tree search actually completed\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "test = ['score' not in state for state in states]\n",
    "complete_states = [state for state in states if state['score'] == float('inf') or state['score'] == float('-inf')]\n",
    "print(len(complete_states))\n",
    "board_full_c, player_pos_c, y_c = prepare_data_for_model(complete_states,'score')\n",
    "y_c[y_c==float('inf')] = 1\n",
    "y_c[y_c==float('-inf')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(set(list(np.reshape(y_c,[-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 16, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 16, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 16, 3)         0           input_10[0][0]                   \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_61 (ConvByMov (None, 16, 8)         240         concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, 16, 8)         32          conv_by_move_layer_61[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 16, 8)         0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_62 (ConvByMov (None, 16, 8)         600         activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, 16, 8)         32          conv_by_move_layer_62[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 16, 8)         0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_63 (ConvByMov (None, 16, 8)         600         activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_63[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_29 (Add)                     (None, 16, 8)         0           conv_by_move_layer_61[0][0]      \n",
      "                                                                   dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, 16, 8)         32          add_29[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 16, 8)         0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_64 (ConvByMov (None, 16, 8)         600         activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, 16, 8)         32          conv_by_move_layer_64[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, 16, 8)         0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_65 (ConvByMov (None, 16, 8)         600         activation_64[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_65[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_30 (Add)                     (None, 16, 8)         0           add_29[0][0]                     \n",
      "                                                                   dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, 16, 8)         32          add_30[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, 16, 8)         0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_66 (ConvByMov (None, 16, 8)         600         activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, 16, 8)         32          conv_by_move_layer_66[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 16, 8)         0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_67 (ConvByMov (None, 16, 8)         600         activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_67[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_31 (Add)                     (None, 16, 8)         0           add_30[0][0]                     \n",
      "                                                                   dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, 16, 8)         32          add_31[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 16, 8)         0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_68 (ConvByMov (None, 16, 8)         600         activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, 16, 8)         32          conv_by_move_layer_68[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, 16, 8)         0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_69 (ConvByMov (None, 16, 8)         600         activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_69[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_32 (Add)                     (None, 16, 8)         0           add_31[0][0]                     \n",
      "                                                                   dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 16, 8)         32          add_32[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, 16, 8)         0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_70 (ConvByMov (None, 16, 8)         600         activation_69[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 16, 8)         32          conv_by_move_layer_70[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, 16, 8)         0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_71 (ConvByMov (None, 16, 8)         600         activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_71[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_33 (Add)                     (None, 16, 8)         0           add_32[0][0]                     \n",
      "                                                                   dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 16, 8)         32          add_33[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, 16, 8)         0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_72 (ConvByMov (None, 16, 8)         600         activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 16, 8)         32          conv_by_move_layer_72[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, 16, 8)         0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_73 (ConvByMov (None, 16, 8)         600         activation_72[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_73[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_34 (Add)                     (None, 16, 8)         0           add_33[0][0]                     \n",
      "                                                                   dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, 16, 8)         32          add_34[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, 16, 8)         0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_74 (ConvByMov (None, 16, 8)         600         activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, 16, 8)         32          conv_by_move_layer_74[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, 16, 8)         0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_75 (ConvByMov (None, 16, 8)         600         activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_75[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_35 (Add)                     (None, 16, 8)         0           add_34[0][0]                     \n",
      "                                                                   dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, 16, 8)         32          add_35[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, 16, 8)         0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_76 (ConvByMov (None, 16, 8)         600         activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 16, 8)         32          conv_by_move_layer_76[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, 16, 8)         0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_77 (ConvByMov (None, 16, 8)         600         activation_76[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 16, 8)         0           conv_by_move_layer_77[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_36 (Add)                     (None, 16, 8)         0           add_35[0][0]                     \n",
      "                                                                   dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, 16, 8)         0           add_36[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 16, 10)        0           activation_77[0][0]              \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 160)           0           concatenate_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 10)            1610        flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             11          dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 11,973\n",
      "Trainable params: 11,717\n",
      "Non-trainable params: 256\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from neural.keras_utils import deep_model_fun\n",
    "# width AND depth matter! (32, 8 seem about optimal on this dataset)\n",
    "deep_model = deep_model_fun(num_features =8, num_res_modules = 8, drop_rate = 0.05, activation = 'sigmoid')\n",
    "deep_model.summary()\n",
    "#deep_model.compile(optimizer = 'adam',  loss='binary_crossentropy', metrics =['acc'])deep_model.compile(optimizer = 'adam',  loss='binary_crossentropy', metrics =['acc'])\n",
    "deep_model.compile(optimizer = 'adam',  loss='mean_squared_error', metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1016 samples, validate on 255 samples\n",
      "Epoch 1/30\n",
      "1016/1016 [==============================] - 14s - loss: 0.3331 - acc: 0.5719 - val_loss: 0.2948 - val_acc: 0.6863\n",
      "Epoch 2/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.2537 - acc: 0.6732 - val_loss: 0.2612 - val_acc: 0.7176\n",
      "Epoch 3/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.2303 - acc: 0.6959 - val_loss: 0.2434 - val_acc: 0.7216\n",
      "Epoch 4/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.2221 - acc: 0.6978 - val_loss: 0.2355 - val_acc: 0.7216\n",
      "Epoch 5/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.2154 - acc: 0.7057 - val_loss: 0.2295 - val_acc: 0.7216\n",
      "Epoch 6/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.2016 - acc: 0.7352 - val_loss: 0.2292 - val_acc: 0.7216\n",
      "Epoch 7/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1947 - acc: 0.7402 - val_loss: 0.2190 - val_acc: 0.7216\n",
      "Epoch 8/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1866 - acc: 0.7677 - val_loss: 0.2129 - val_acc: 0.7137\n",
      "Epoch 9/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1799 - acc: 0.7785 - val_loss: 0.1712 - val_acc: 0.8157\n",
      "Epoch 10/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1729 - acc: 0.7894 - val_loss: 0.2014 - val_acc: 0.7294\n",
      "Epoch 11/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1550 - acc: 0.8179 - val_loss: 0.1498 - val_acc: 0.8078\n",
      "Epoch 12/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1494 - acc: 0.8219 - val_loss: 0.1592 - val_acc: 0.8196\n",
      "Epoch 13/30\n",
      "1016/1016 [==============================] - 7s - loss: 0.1526 - acc: 0.8209 - val_loss: 0.1873 - val_acc: 0.7804\n",
      "Epoch 14/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1655 - acc: 0.8041 - val_loss: 0.1522 - val_acc: 0.8314\n",
      "Epoch 15/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1427 - acc: 0.8514 - val_loss: 0.1532 - val_acc: 0.8314\n",
      "Epoch 16/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1424 - acc: 0.8543 - val_loss: 0.1581 - val_acc: 0.8314\n",
      "Epoch 17/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1492 - acc: 0.8346 - val_loss: 0.2064 - val_acc: 0.7412\n",
      "Epoch 18/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1359 - acc: 0.8563 - val_loss: 0.1643 - val_acc: 0.8235\n",
      "Epoch 19/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1314 - acc: 0.8602 - val_loss: 0.1781 - val_acc: 0.8118\n",
      "Epoch 20/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1231 - acc: 0.8740 - val_loss: 0.1566 - val_acc: 0.8353\n",
      "Epoch 21/30\n",
      "1016/1016 [==============================] - 6s - loss: 0.1230 - acc: 0.8799 - val_loss: 0.1485 - val_acc: 0.8471\n",
      "Epoch 22/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1187 - acc: 0.8799 - val_loss: 0.1615 - val_acc: 0.8118\n",
      "Epoch 23/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1127 - acc: 0.8917 - val_loss: 0.1651 - val_acc: 0.8157\n",
      "Epoch 24/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1170 - acc: 0.8868 - val_loss: 0.1608 - val_acc: 0.7961\n",
      "Epoch 25/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1114 - acc: 0.8888 - val_loss: 0.1731 - val_acc: 0.8000\n",
      "Epoch 26/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1215 - acc: 0.8770 - val_loss: 0.1550 - val_acc: 0.8392\n",
      "Epoch 27/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1089 - acc: 0.8967 - val_loss: 0.1545 - val_acc: 0.8235\n",
      "Epoch 28/30\n",
      "1016/1016 [==============================] - 5s - loss: 0.1222 - acc: 0.8829 - val_loss: 0.1560 - val_acc: 0.8471\n",
      "Epoch 29/30\n",
      " 320/1016 [========>.....................] - ETA: 4s - loss: 0.1216 - acc: 0.8875"
     ]
    }
   ],
   "source": [
    "deep_model.fit([player_pos_c, board_full_c], y_c, batch_size = 16, epochs=30, verbose =1, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Illegal move!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8c4eea2fecac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgame1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgame2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgame3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# board, pos, _ = possible_moves_for_model(game3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# print(board.shape, pos.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Dropbox\\GitHub\\aind\\aind-isolation\\neural\\neural_agent.py\u001b[0m in \u001b[0;36mapply_move\u001b[1;34m(game, move)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_legal_moves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Illegal move!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mnew_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'game'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mnew_board\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Illegal move!"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from copy import copy\n",
    "from neural.neural_agent import apply_move, get_best_move_from_model\n",
    "\n",
    "board = np.ones(49)\n",
    "#print(list(board))\n",
    "board.sum()\n",
    "my_pos = None\n",
    "other_pos = None\n",
    "game = {'pos': np.array([my_pos, other_pos]), 'game': board}\n",
    "game1 = apply_move(game, 0)\n",
    "game2 = apply_move(game1, 1)\n",
    "game3 = apply_move(game2, 15)\n",
    "# board, pos, _ = possible_moves_for_model(game3)\n",
    "# print(board.shape, pos.shape)\n",
    "get_best_move_from_model(game3, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from neural.neural_agent import NeuralAgent\n",
    "my_agent = NeuralAgent(deep_model)\n",
    "my_agent.get_move(game3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tournament import tournament, Agent, RandomPlayer\n",
    "from neural.neural_agent import NeuralAgent\n",
    "\n",
    "my_agent = NeuralAgent(deep_model)\n",
    "tournament(num_matches=20, time_limit=float('inf'), \n",
    "           test_agents=[Agent(my_agent,\"Neural Agent\")])\n",
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort all games by number of moves. \n",
    "states_by_num_moves = [[] for _ in range(BOARD_SIZE)]\n",
    "\n",
    "for state in states:\n",
    "    moves_made = BOARD_SIZE - state['game'].sum()\n",
    "    states_by_num_moves[int(moves_made)].append(state)\n",
    "    \n",
    "for n in range(BOARD_SIZE):\n",
    "    print(n,len(states_by_num_moves[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iteratively populate all non-+-inf values in layer n from evaluating model in layer n+1, then include these into the fitting set\n",
    "# after each pass, refresh the values for earlier layers\n",
    "def recursively_fill_scores(states, model = deep_model):\n",
    "    print(len(states))\n",
    "    scores = np.zeros([len(states)])\n",
    "    for n,state in enumerate(states):\n",
    "        if state['score']  == float('inf'):\n",
    "            scores[n] = 1\n",
    "        elif state['score'] == float('-inf'):\n",
    "            scores[n] = 0\n",
    "        else:\n",
    "            _ , scores[n] = get_best_move_from_model(state, model)\n",
    "        if n%1000 == 0:\n",
    "            print(n)\n",
    "    return scores\n",
    "\n",
    "prepared_data = [None for _ in range(49)]\n",
    "\n",
    "for n in range(18,BOARD_SIZE):\n",
    "    if len(states_by_num_moves[n]):\n",
    "        board, pos, _  = prepare_data_for_model( states_by_num_moves[n], None) # board, player_pos, score\n",
    "        scores = recursively_fill_scores( states_by_num_moves[n])\n",
    "        prepared_data[n] = (pos, board, scores)\n",
    "        print(len(scores),len(set(list(scores))))\n",
    "# TODO: is my position always first in those dumps???\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
