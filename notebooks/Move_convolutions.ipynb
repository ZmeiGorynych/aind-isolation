{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the symmetry-corrected indices for move-based convolution\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the coefficient generation logic the naive way\n",
    "cell = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[  0.   0.  39.   0.  39.   0.   0.]\n",
      " [  0.  37.   0.   0.   0.  37.   0.]\n",
      " [  0.   0.   0.   9.   0.   0.   0.]\n",
      " [  0.  36.   0.   0.   0.  36.   0.]\n",
      " [  0.   0.  38.   0.  38.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# display-only code, to visually check the coeffs are in the correct locations on the board\n",
    "from neural.neural_ import to_pair, generate_all_moves_by_index, move_convolution_indices\n",
    "\n",
    "all_inds, num_coeffs = move_convolution_indices()\n",
    "num_coeffs -= 10 # the first 10 in the above function are biases, don't need them\n",
    "num_biases = 10\n",
    "num_fields = 7*7\n",
    "\n",
    "cell = cell+1\n",
    "tmp = all_inds[cell]\n",
    "a = np.zeros([7,7])\n",
    "for (ind, coeff) in tmp[1:]:\n",
    "    pair = to_pair(ind)\n",
    "    a[pair[0],pair[1]] = coeff - 9\n",
    "\n",
    "print(to_pair(cell))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2]\n",
      "[[[-15.65185452   1.91709328]\n",
      "  [ 26.72372246   1.52010012]\n",
      "  [ -6.86462402  -0.48497367]]\n",
      "\n",
      " [[-20.92775726   2.48585844]\n",
      "  [ 33.23313141   0.52431291]\n",
      "  [ -9.04220009  -0.66439515]]]\n"
     ]
    }
   ],
   "source": [
    "# try calling conv_stack directly from Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from neural.tensorflow_utils import conv_stack\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    in_fields_np = np.ones([2,num_fields])\n",
    "    in_fields_np[0,3] = 0\n",
    "    in_fields_np[0,5] = 0\n",
    "    my_pos = np.array([24, 24])\n",
    "    other_pos =  np.array([33,33])\n",
    "    inputs_np = np.concatenate([in_fields_np, my_pos[:,None], other_pos[:,None]],\n",
    "                              1)\n",
    "    #print(inputs_np.shape)\n",
    "    inputs =tf.constant(inputs_np)# tf.placeholder(shape =[None, num_fields+2], dtype = tf.float32) #\n",
    "    #print(sess.run(inputs))\n",
    "    out = conv_stack(inputs, 5,sess)\n",
    "    \n",
    "    dummy = np.array([50,50])[:,None]\n",
    "    #print(sess.run(get_random_index(inputs, tf.constant(dummy))))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    stack_result = sess.run(out)#, feed_dict={inputs:inputs_np})\n",
    "    print(stack_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load game simulation data\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "from neural.data_utils import load_simulation_data\n",
    "\n",
    "fn = '../data/states.pickle'\n",
    "try:\n",
    "    with open(fn, 'rb') as f:\n",
    "        states = pickle.load(f)\n",
    "except:\n",
    "    files = glob.glob('../data/ID_x2_1000ms/result_ID*.pickle')\n",
    "    #print(files)\n",
    "    depths =load_simulation_data(files)\n",
    "    keys = list(depths.keys())\n",
    "    #print(keys)\n",
    "    games = depths[keys[0]]\n",
    "    #print(games[0])\n",
    "    states = [state for game in games for state in game] \n",
    "    print(len(states))\n",
    "    with open(fn, 'wb') as f:\n",
    "        pickle.dump(states,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 49, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 49, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 49, 3)         0           input_2[0][0]                    \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_1 (ConvByMove (None, 49, 4)         532         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 49, 4)         16          conv_by_move_layer_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 49, 4)         0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_2 (ConvByMove (None, 49, 4)         696         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 49, 4)         16          conv_by_move_layer_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 49, 4)         0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_3 (ConvByMove (None, 49, 4)         696         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 49, 4)         0           conv_by_move_layer_1[0][0]       \n",
      "                                                                   conv_by_move_layer_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 49, 4)         16          add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 49, 4)         0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_4 (ConvByMove (None, 49, 4)         696         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 49, 4)         16          conv_by_move_layer_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 49, 4)         0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_5 (ConvByMove (None, 49, 4)         696         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 49, 4)         0           add_1[0][0]                      \n",
      "                                                                   conv_by_move_layer_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 49, 4)         0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 49, 6)         0           activation_5[0][0]               \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 294)           0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            2950        flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             11          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6,341\n",
      "Trainable params: 6,309\n",
      "Non-trainable params: 32\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# attempt to fit a simple score\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Activation\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "from neural.keras_utils import ConvByMoveLayer\n",
    "\n",
    "player_pos_one_hot = Input(shape = [49, 2])\n",
    "board_state = Input(shape=[49,1])\n",
    "mask = board_state\n",
    "num_features = 4\n",
    "\n",
    "def ResNetLayerFun(x, num_features = 3, mask = None):\n",
    "    tmp = BatchNormalization()(x)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = BatchNormalization()(tmp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    return Add()([x,tmp])\n",
    "\n",
    "#tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "out = Concatenate()([board_state, player_pos_one_hot])\n",
    "out = ConvByMoveLayer(num_features, mask)(out)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = Activation('relu')(out)\n",
    "out = Concatenate()([out, player_pos_one_hot])\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation = 'relu')(out)\n",
    "out = Dense(1)(out)\n",
    "\n",
    "model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam',  loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984694\n"
     ]
    }
   ],
   "source": [
    "from neural.data_utils import prepare_data_for_model\n",
    "board_full, player_pos, y = prepare_data_for_model(states)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "308992/984694 [========>.....................] - ETA: 70s - loss: 1.1580"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-2ac188744190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mplayer_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboard_full\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\egork\\Anaconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([player_pos, board_full],y, batch_size = 256, epochs=10, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4795\n"
     ]
    }
   ],
   "source": [
    "# Now let's get all those games where tree search actually completed\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "complete_states = [state for state in states if state['score'] == float('inf') or state['score'] == float('-inf')]\n",
    "print(len(complete_states))\n",
    "board_full_c, player_pos_c, y_c = prepare_data_for_model(complete_states,'score')\n",
    "y_c[y_c==float('inf')] = 1\n",
    "y_c[y_c==float('-inf')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(set(list(np.reshape(y_c,[-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 49, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 49, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 49, 3)         0           input_6[0][0]                    \n",
      "                                                                   input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_39 (ConvByMov (None, 49, 16)        2128        concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 49, 16)        64          conv_by_move_layer_39[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 49, 16)        0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_40 (ConvByMov (None, 49, 16)        10656       activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 49, 16)        64          conv_by_move_layer_40[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 49, 16)        0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_41 (ConvByMov (None, 49, 16)        10656       activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_41[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_19 (Add)                     (None, 49, 16)        0           conv_by_move_layer_39[0][0]      \n",
      "                                                                   dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 49, 16)        64          add_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 49, 16)        0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_42 (ConvByMov (None, 49, 16)        10656       activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 49, 16)        64          conv_by_move_layer_42[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 49, 16)        0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_43 (ConvByMov (None, 49, 16)        10656       activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_43[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_20 (Add)                     (None, 49, 16)        0           add_19[0][0]                     \n",
      "                                                                   dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 49, 16)        64          add_20[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 49, 16)        0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_44 (ConvByMov (None, 49, 16)        10656       activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 49, 16)        64          conv_by_move_layer_44[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 49, 16)        0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_45 (ConvByMov (None, 49, 16)        10656       activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_45[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_21 (Add)                     (None, 49, 16)        0           add_20[0][0]                     \n",
      "                                                                   dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 49, 16)        64          add_21[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 49, 16)        0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_46 (ConvByMov (None, 49, 16)        10656       activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 49, 16)        64          conv_by_move_layer_46[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 49, 16)        0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_47 (ConvByMov (None, 49, 16)        10656       activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_47[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_22 (Add)                     (None, 49, 16)        0           add_21[0][0]                     \n",
      "                                                                   dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 49, 16)        64          add_22[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 49, 16)        0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_48 (ConvByMov (None, 49, 16)        10656       activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, 49, 16)        64          conv_by_move_layer_48[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 49, 16)        0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_49 (ConvByMov (None, 49, 16)        10656       activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_49[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_23 (Add)                     (None, 49, 16)        0           add_22[0][0]                     \n",
      "                                                                   dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, 49, 16)        64          add_23[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 49, 16)        0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_50 (ConvByMov (None, 49, 16)        10656       activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, 49, 16)        64          conv_by_move_layer_50[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 49, 16)        0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_51 (ConvByMov (None, 49, 16)        10656       activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_51[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_24 (Add)                     (None, 49, 16)        0           add_23[0][0]                     \n",
      "                                                                   dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 49, 16)        64          add_24[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 49, 16)        0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_52 (ConvByMov (None, 49, 16)        10656       activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 49, 16)        64          conv_by_move_layer_52[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 49, 16)        0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_53 (ConvByMov (None, 49, 16)        10656       activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_53[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_25 (Add)                     (None, 49, 16)        0           add_24[0][0]                     \n",
      "                                                                   dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, 49, 16)        64          add_25[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 49, 16)        0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_54 (ConvByMov (None, 49, 16)        10656       activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, 49, 16)        64          conv_by_move_layer_54[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 49, 16)        0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_55 (ConvByMov (None, 49, 16)        10656       activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_55[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_26 (Add)                     (None, 49, 16)        0           add_25[0][0]                     \n",
      "                                                                   dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, 49, 16)        64          add_26[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 49, 16)        0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_56 (ConvByMov (None, 49, 16)        10656       activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, 49, 16)        64          conv_by_move_layer_56[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 49, 16)        0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_57 (ConvByMov (None, 49, 16)        10656       activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_57[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_27 (Add)                     (None, 49, 16)        0           add_26[0][0]                     \n",
      "                                                                   dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, 49, 16)        64          add_27[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, 49, 16)        0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_58 (ConvByMov (None, 49, 16)        10656       activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, 49, 16)        64          conv_by_move_layer_58[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 49, 16)        0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_59 (ConvByMov (None, 49, 16)        10656       activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_59[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_28 (Add)                     (None, 49, 16)        0           add_27[0][0]                     \n",
      "                                                                   dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, 49, 16)        64          add_28[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 49, 16)        0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_60 (ConvByMov (None, 49, 16)        10656       activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, 49, 16)        64          conv_by_move_layer_60[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 49, 16)        0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_61 (ConvByMov (None, 49, 16)        10656       activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_61[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_29 (Add)                     (None, 49, 16)        0           add_28[0][0]                     \n",
      "                                                                   dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, 49, 16)        64          add_29[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 49, 16)        0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_62 (ConvByMov (None, 49, 16)        10656       activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, 49, 16)        64          conv_by_move_layer_62[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 49, 16)        0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_63 (ConvByMov (None, 49, 16)        10656       activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_63[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_30 (Add)                     (None, 49, 16)        0           add_29[0][0]                     \n",
      "                                                                   dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, 49, 16)        64          add_30[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 49, 16)        0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_64 (ConvByMov (None, 49, 16)        10656       activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, 49, 16)        64          conv_by_move_layer_64[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, 49, 16)        0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_65 (ConvByMov (None, 49, 16)        10656       activation_64[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_65[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_31 (Add)                     (None, 49, 16)        0           add_30[0][0]                     \n",
      "                                                                   dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, 49, 16)        64          add_31[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, 49, 16)        0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_66 (ConvByMov (None, 49, 16)        10656       activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, 49, 16)        64          conv_by_move_layer_66[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 49, 16)        0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_67 (ConvByMov (None, 49, 16)        10656       activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_67[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_32 (Add)                     (None, 49, 16)        0           add_31[0][0]                     \n",
      "                                                                   dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 49, 16)        64          add_32[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 49, 16)        0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_68 (ConvByMov (None, 49, 16)        10656       activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 49, 16)        64          conv_by_move_layer_68[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, 49, 16)        0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_69 (ConvByMov (None, 49, 16)        10656       activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_69[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_33 (Add)                     (None, 49, 16)        0           add_32[0][0]                     \n",
      "                                                                   dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 49, 16)        64          add_33[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, 49, 16)        0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_70 (ConvByMov (None, 49, 16)        10656       activation_69[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 49, 16)        64          conv_by_move_layer_70[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, 49, 16)        0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_71 (ConvByMov (None, 49, 16)        10656       activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 49, 16)        0           conv_by_move_layer_71[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_34 (Add)                     (None, 49, 16)        0           add_33[0][0]                     \n",
      "                                                                   dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, 49, 16)        0           add_34[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 49, 18)        0           activation_71[0][0]              \n",
      "                                                                   input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 882)           0           concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            8830        flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2)             22          dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 354,020\n",
      "Trainable params: 352,996\n",
      "Non-trainable params: 1,024\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Activation, Dropout\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "player_pos_one_hot = Input(shape = [49, 2])\n",
    "board_state = Input(shape=[49,1])\n",
    "mask = board_state\n",
    "num_features = 16\n",
    "num_res_modules = 16\n",
    "drop_rate = 0.1\n",
    "\n",
    "def ResNetLayerFun(x, num_features = 3, mask = None):\n",
    "    tmp = BatchNormalization()(x)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = BatchNormalization()(tmp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = Dropout(drop_rate)(tmp)\n",
    "    return Add()([x,tmp])\n",
    "\n",
    "#tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "out = Concatenate()([board_state, player_pos_one_hot])\n",
    "out = ConvByMoveLayer(num_features, mask)(out)\n",
    "for _ in range(num_res_modules):\n",
    "    out = ResNetLayerFun(out, num_features, mask)\n",
    "out = Activation('relu')(out)\n",
    "out = Concatenate()([out, player_pos_one_hot])\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation = 'relu')(out)\n",
    "out = Dense(2, activation = 'softmax')(out)\n",
    "\n",
    "deep_model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "deep_model.summary()\n",
    "deep_model.compile(optimizer = 'adam',  loss='categorical_crossentropy', metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4315 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "4315/4315 [==============================] - 4s - loss: 0.2558 - acc: 0.9041 - val_loss: 0.2792 - val_acc: 0.8896\n",
      "Epoch 2/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.2307 - acc: 0.9131 - val_loss: 0.2171 - val_acc: 0.9250\n",
      "Epoch 3/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.2055 - acc: 0.9196 - val_loss: 0.2476 - val_acc: 0.9229\n",
      "Epoch 4/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.1828 - acc: 0.9289 - val_loss: 0.2723 - val_acc: 0.9062\n",
      "Epoch 5/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.1686 - acc: 0.9351 - val_loss: 0.2534 - val_acc: 0.9021\n",
      "Epoch 6/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.1605 - acc: 0.9363 - val_loss: 0.2563 - val_acc: 0.9021\n",
      "Epoch 7/10\n",
      "4315/4315 [==============================] - 4s - loss: 0.1569 - acc: 0.9353 - val_loss: 0.3352 - val_acc: 0.8917\n",
      "Epoch 8/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.1340 - acc: 0.9462 - val_loss: 0.2969 - val_acc: 0.9021\n",
      "Epoch 9/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.1208 - acc: 0.9499 - val_loss: 0.3498 - val_acc: 0.9062\n",
      "Epoch 10/10\n",
      "4315/4315 [==============================] - 3s - loss: 0.1080 - acc: 0.9560 - val_loss: 0.3694 - val_acc: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24861d85400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "deep_model.fit([player_pos_c, board_full_c],to_categorical(y_c, num_classes=2), batch_size = 256, epochs=10, verbose =1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from copy import copy\n",
    "\n",
    "# 'pos' is [pos of player about to move, other_pos]\n",
    "# 'game' is a vector of 0s for used fields, 1s for available fields\n",
    "\n",
    "#SimpleGame = namedtuple(\"Simple_game\", [\"moving_player_pos\",\"other_player_pos\", \"board\"])\n",
    "move_dict = generate_all_moves_by_index()\n",
    "\n",
    "def get_legal_moves(game):\n",
    "    if game['pos'][0] is None:\n",
    "        return [m for m in range(49) if game['game'][m] == 1]\n",
    "    else:\n",
    "        moves = move_dict[game['pos'][0]]\n",
    "        return [m for m in moves if game['game'][m] == 1]\n",
    "\n",
    "def apply_move(game, move):\n",
    "    if not move in get_legal_moves(game):\n",
    "        raise ValueError('Illegal move!')\n",
    "    new_board = copy(game['game'])\n",
    "    new_board[move] = 0\n",
    "    other_pos = move\n",
    "    moving_pos = game['pos'][1]\n",
    "    return {'game': new_board, 'pos': np.array([moving_pos, other_pos])}\n",
    "\n",
    "def get_best_move_from_model(game, model = deep_model):\n",
    "    moves = get_legal_moves(game)\n",
    "    tmp = [apply_move(game, move) for move in moves]\n",
    "    board, pos, _ = prepare_data_for_model(tmp,None)\n",
    "    valuations = model.predict([pos, board])[:,0]\n",
    "    best_ind = np.argmax(valuations)\n",
    "    #print(best_ind)\n",
    "    return moves[best_ind], valuations[best_ind]\n",
    "        \n",
    "    \n",
    "    \n",
    "board = np.ones(49)\n",
    "print(list(board))\n",
    "board.sum()\n",
    "my_pos = None\n",
    "other_pos = None\n",
    "game = {'pos': np.array([my_pos, other_pos]), 'game': board}\n",
    "game1 = apply_move(game, 0)\n",
    "game2 = apply_move(game1, 1)\n",
    "print(get_legal_moves(game2))\n",
    "game3 = apply_move(game2, 15)\n",
    "# board, pos, _ = possible_moves_for_model(game3)\n",
    "# print(board.shape, pos.shape)\n",
    "get_best_move_from_model(game3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort all games by number of moves. \n",
    "states_by_num_moves = [[] for _ in range(49)]\n",
    "\n",
    "for state in states:\n",
    "    moves_made = 49 - state['game'].sum()\n",
    "    states_by_num_moves[int(moves_made)].append(state)\n",
    "    \n",
    "for n in range(49):\n",
    "    print(n,len(states_by_num_moves[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively populate all non-+-inf values in layer n from evaluating model in layer n+1, then include these into the fitting set\n",
    "# after each pass, refresh the values for earlier layers\n",
    "def recursively_fill_scores(states, model = deep_model):\n",
    "    print(len(states))\n",
    "    scores = np.zeros([len(states)])\n",
    "    for n,state in enumerate(states):\n",
    "        if state['score']  == float('inf'):\n",
    "            scores[n] = 1\n",
    "        elif state['score'] == float('-inf'):\n",
    "            scores[n] = 0\n",
    "        else:\n",
    "            _ , scores[n] = get_best_move_from_model(state, model)\n",
    "        if n%1000 == 0:\n",
    "            print(n)\n",
    "    return scores\n",
    "\n",
    "prepared_data = [None for _ in range(49)]\n",
    "\n",
    "for n in range(18,49):\n",
    "    if len(states_by_num_moves[n]):\n",
    "        board, pos, _  = prepare_data_for_model( states_by_num_moves[n], None) # board, player_pos, score\n",
    "        scores = recursively_fill_scores( states_by_num_moves[n])\n",
    "        prepared_data[n] = (pos, board, scores)\n",
    "        print(len(scores),len(set(list(scores))))\n",
    "# TODO: is my position always first in those dumps???\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
