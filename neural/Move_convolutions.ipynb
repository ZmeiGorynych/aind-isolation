{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# generate the symmetry-corrected indices for move-based convolution\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from neural import generate_all_moves_by_index, move_convolution_indices\n",
    "#generate_all_moves_by_index()\n",
    "all_inds, num_coeffs = move_convolution_indices()\n",
    "num_coeffs -= 20 # the first 10 in the above function are biases, don't need them, the next 10 are self coeffs\n",
    "num_biases = 10\n",
    "print(num_coeffs)\n",
    "num_fields = 7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the coefficient generation logic the naive way\n",
    "cell = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[  0.   0.  36.   0.  36.   0.   0.]\n",
      " [  0.  37.   0.   0.   0.  37.   0.]\n",
      " [  0.   0.   0.   9.   0.   0.   0.]\n",
      " [  0.  38.   0.   0.   0.  38.   0.]\n",
      " [  0.   0.  39.   0.  39.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "from neural import to_pair\n",
    "cell = cell+1\n",
    "tmp = all_inds[cell]\n",
    "a = np.zeros([7,7])\n",
    "for (ind, coeff) in tmp[1:]:\n",
    "    pair = to_pair(ind)\n",
    "    a[pair[0],pair[1]] = coeff - 9\n",
    "\n",
    "print(to_pair(cell))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_to_board(vec):\n",
    "    board = np.reshape(vec,[7,7])\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert that dict into a 3d-tensor,\n",
    "# [in_field, out_field, coeff_ind]\n",
    "\n",
    "conv_map = np.zeros([num_fields, num_fields, num_coeffs])\n",
    "bias_map = np.zeros([num_fields, num_biases])\n",
    "for cell in range(num_fields):\n",
    "    tmp = all_inds[cell]\n",
    "    bias_map[cell, tmp[0][1]] = 1\n",
    "    #print(cell,tmp[0])\n",
    "    for (ind, coeff) in tmp[1:]:\n",
    "        if coeff>=20:\n",
    "            pair = to_pair(ind)\n",
    "            conv_map[cell, ind, coeff-20] = 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's do the convolution in Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_mapping = tf.constant(conv_map,dtype=tf.float32, name = 'conv_mapping')  \n",
    "bias_mapping = tf.constant(bias_map,dtype=tf.float32, name = 'bias_mapping')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolve_by_moves(in_fields, mask, this_conv_coeffs, biases): \n",
    "    '''\n",
    "    in_fields is a batch of tensors [batch_size, num_fields, num_channels]\n",
    "    mask is a tensor of 0s and 1s [num_fields]\n",
    "    so conv_coeffs must have size [num_coeffs, channels_in, channels_out]\n",
    "    '''\n",
    "    \n",
    "    tmp = tf.tensordot(conv_mapping, this_conv_coeffs, [[2],[0]])\n",
    "    #print(sess.run([tf.shape(tmp), tf.shape(in_fields)]))\n",
    "    tmp2 = tf.matmul(tf.cast(in_fields,tf.float32), tmp)\n",
    "    out = tf.multiply(tmp2, tf.cast(mask,tf.float32))\n",
    "    # TODO: biases must also be symmetry-corrected!\n",
    "    return out + biases\n",
    "\n",
    "# this wrapper just defines the Variables, to be replaced by a Keras wrapper\n",
    " # approx avg number of inputs is 6 or so, so normalize init weights accordingly\n",
    "def convolve_by_moves_with_coeffs(in_fields, mask, \n",
    "                      wgt_init = tf.truncated_normal(shape=[num_coeffs],stddev = 1/2.5,\n",
    "                                                     dtype=tf.float32)):\n",
    "    this_conv_coeffs = tf.Variable(wgt_init)\n",
    "    # TODO: biases must also be symmetry-corrected!\n",
    "    biases = tf.Variable(np.zeros(num_fields), dtype = tf.float32) \n",
    "    return convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases, sess=None): \n",
    "    '''\n",
    "    in_fields is a batch of tensors [batch_size, num_fields, num_channels]\n",
    "    mask is a tensor of 0s and 1s [num_fields]\n",
    "    so conv_coeffs must have size [num_coeffs, channels_in, channels_out]\n",
    "    '''\n",
    "    input_dim = in_fields.get_shape().as_list()\n",
    "    if len(input_dim) == 2: # just batch and fields\n",
    "        in_fields = tf.expand_dims(in_fields,2) # add the channel dimension\n",
    "    # inputs conv_mapping[i,j,k], this_conv_coeffs[k,m,l], output tmp[i,j,m,l]\n",
    "    tmp = tf.tensordot(conv_mapping, this_conv_coeffs, [[2],[0]]) \n",
    "    #print(sess.run([tf.shape(tmp), tf.shape(in_fields)]))\n",
    "    # in_fields[b,j,m], output is tmp2[b,i,l]\n",
    "    tmp2 = tf.tensordot(tf.cast(in_fields,tf.float32), tmp, [[1,2],[1,2]])\n",
    "    \n",
    "    # bias_mapping[i,k], biases[k,l], bias_term should be [b,i,l] but in this line just get [i,l]: \n",
    "    tmp_bias = tf.tensordot(bias_mapping, biases,[[1],[0]])\n",
    "\n",
    "    out = tmp2 + tf.expand_dims(tmp_bias, 0) # use broadcasting to add biases to each batch\n",
    "    \n",
    "    if mask is not None:\n",
    "        # mask is [b,i], batches x num_fields, need to apply to all channels of output - use broadcasting\n",
    "        if len(mask.get_shape()) == 2:\n",
    "            mask = tf.expand_dims(mask, 2)\n",
    "        out = tf.multiply(out, tf.cast(mask,tf.float32))\n",
    "    return out\n",
    "\n",
    "# this wrapper just defines the Variables, to be replaced by a Keras wrapper\n",
    " # approx avg number of inputs is 6 or so, so normalize init weights accordingly\n",
    "def ch_convolve_by_moves_with_coeffs(in_fields, mask, out_channels, wgt_init = None, sess=None):\n",
    "    in_channels = in_fields.get_shape().as_list()[-1]\n",
    "    #print(sess.run(tf.shape(in_fields)[-1]))\n",
    "    #print(in_fields.get_shape().as_list())\n",
    "    if not wgt_init:\n",
    "        wgt_init = tf.truncated_normal(shape=[num_coeffs,in_channels, out_channels],stddev = 1/2.5,\n",
    "                                                     dtype=tf.float32)\n",
    "    this_conv_coeffs = tf.Variable(wgt_init)\n",
    "    \n",
    "    biases = tf.Variable(np.zeros([num_biases, out_channels]), dtype = tf.float32)\n",
    "    return ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Show all coefficient indices\n",
    "# with tf.Session() as sess:\n",
    "#     for ind in range(49):\n",
    "#         in_fields_np = np.zeros([2,num_fields])\n",
    "#         in_fields_np[0,3] = 1\n",
    "#         in_fields_np[0,5] = 1\n",
    "#         in_fields_np[1,ind] = 1\n",
    "#         in_fields = tf.constant(np.array(in_fields_np))\n",
    "\n",
    "#         mask = tf.constant(np.ones(in_fields_np[0].shape))\n",
    "#         out = convolve_by_moves(in_fields, mask, np.ones(num_coeffs))\n",
    "#         out_2 = convolve_by_moves(out, mask, np.ones(num_coeffs))\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         print(vec_to_board(sess.run(out_2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_index(x, ind, batch_size, sess = None):\n",
    "    '''\n",
    "    x: [batch_size, num_fields]\n",
    "    ind: [batch_size,2] # 2 random indexes (me and opponent) I want to grab in the corresponding row\n",
    "    '''\n",
    "    #\n",
    "    batch_ind = tf.constant(np.array(range(batch_size))[:,None])\n",
    "    batch_nums = tf.cast(batch_ind, tf.int32)\n",
    "    ind =tf.cast(ind, tf.int32)\n",
    "    ind1 = tf.slice(ind,[0,0],[-1,1])\n",
    "    ind2 = tf.slice(ind,[0,1],[-1,1])\n",
    "    ind_ext1 = tf.concat([batch_nums,ind1],1)\n",
    "    ind_ext2 = tf.concat([batch_nums, ind2],1)\n",
    "    out1 =tf.expand_dims(tf.gather_nd(x,ind_ext1),2)\n",
    "    out2 =tf.expand_dims(tf.gather_nd(x,ind_ext2),2)\n",
    "    out = tf.concat([out1,out2],2)\n",
    "    print(sess.run(tf.shape(out)))\n",
    "    return out\n",
    "\n",
    "def conv_stack(inputs, num_layers, sess = None):\n",
    "    '''\n",
    "    in_fields: [batch_size, num_fields]\n",
    "    num_layers: int\n",
    "    my_pos: [batch_size, 1]\n",
    "    other_pos: [batch_size, 1]\n",
    "    '''\n",
    "    in_fields = tf.slice(inputs,[0,0],[-1,num_fields])\n",
    "    player_pos = tf.slice(inputs,[0,num_fields],[-1,2])\n",
    "#     print(sess.run(in_fields))\n",
    "#     print(sess.run(tf.shape(my_pos)))\n",
    "#     print(sess.run(tf.shape(other_pos)))\n",
    "    mask = in_fields\n",
    "    out = tf.expand_dims(in_fields,2) # add the channel dimension\n",
    "    for _ in range(num_layers):\n",
    "        out = ch_convolve_by_moves_with_coeffs(out, in_fields, 3, sess=sess)\n",
    "        \n",
    "    player_wgt = tf.Variable(tf.truncated_normal(shape =[1,2],dtype=tf.float32))\n",
    "    #other_wgt = tf.Variable(tf.truncated_normal(shape =[1],dtype=tf.float32))\n",
    "    \n",
    "    batch_size = out.shape[0]\n",
    "    return player_wgt*get_random_index(out, player_pos, batch_size,sess) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2]\n",
      "[[[-95.14674377  -4.39386368]\n",
      "  [-26.99053001   7.03287792]\n",
      "  [-61.09555435   0.90047985]]\n",
      "\n",
      " [[-93.96670532  -5.07419491]\n",
      "  [-27.18621826   7.13246584]\n",
      "  [-59.01132202   0.50100213]]]\n"
     ]
    }
   ],
   "source": [
    "# try calling conv_stack\n",
    "with tf.Session() as sess:\n",
    "    in_fields_np = np.ones([2,num_fields])\n",
    "    in_fields_np[0,3] = 0\n",
    "    in_fields_np[0,5] = 0\n",
    "    my_pos = np.array([24, 24])\n",
    "    other_pos =  np.array([33,33])\n",
    "    inputs_np = np.concatenate([in_fields_np, my_pos[:,None], other_pos[:,None]],\n",
    "                              1)\n",
    "    #print(inputs_np.shape)\n",
    "    inputs =tf.constant(inputs_np)# tf.placeholder(shape =[None, num_fields+2], dtype = tf.float32) #\n",
    "    #print(sess.run(inputs))\n",
    "    out = conv_stack(inputs, 5,sess)\n",
    "    \n",
    "    dummy = np.array([50,50])[:,None]\n",
    "    #print(sess.run(get_random_index(inputs, tf.constant(dummy))))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    stack_result = sess.run(out)#, feed_dict={inputs:inputs_np})\n",
    "    print(stack_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create a Keras model from the above, to simplify fitting: just using Lambda fails as tf.Variables are not recognized by Keras\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Input, Lambda\n",
    "\n",
    "# #model_in = tf.placeholder(tf.float32, shape = (None, 51))\n",
    "# #model_out = conv_stack(model_in, 5)\n",
    "# my_fun = Lambda(lambda x: conv_stack(x, 5))\n",
    "# #my_model = Model(Input(tensor = model_in), outputs = my_fun(model_in))\n",
    "# my_input = Input(shape = [51])\n",
    "# my_output = my_fun(my_input)\n",
    "# my_model = Model(inputs = my_input, outputs = my_output)\n",
    "# my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# So let's create a custom Keras layer instead\n",
    "\n",
    "# def ch_convolve_by_moves_with_coeffs(in_fields, mask, out_channels):\n",
    "#     in_channels = in_fields.get_shape().as_list()[-1]\n",
    "#     wgt_init = tf.truncated_normal(shape=[num_coeffs,in_channels, out_channels],\n",
    "#                                     stddev = 1/2.5,\n",
    "#                                     dtype=tf.float32)\n",
    "#     this_conv_coeffs = tf.Variable(wgt_init)\n",
    "#     biases = tf.Variable(np.zeros([num_biases, out_channels]), dtype = tf.float32)\n",
    "#     return ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.initializers import TruncatedNormal\n",
    "import numpy as np\n",
    "\n",
    "class ConvByMoveLayer(Layer):\n",
    "\n",
    "    def __init__(self, out_channels, mask = None, **kwargs):\n",
    "        self.out_channels = out_channels\n",
    "        self.mask = mask\n",
    "        super(ConvByMoveLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        if len(input_shape)==2:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = input_shape[2]\n",
    "            \n",
    "        init_std = 1/(3*np.sqrt(in_channels*self.out_channels))\n",
    "            \n",
    "        self.conv_coeffs = self.add_weight(name='conv_coeffs', \n",
    "                                      shape=(num_coeffs,in_channels, self.out_channels),\n",
    "                                      initializer=TruncatedNormal(stddev = init_std),\n",
    "                                      trainable=True)\n",
    "        #print((num_coeffs, in_channels, self.out_channels))\n",
    "        self.biases = self.add_weight(name='biases', \n",
    "                                      shape=(num_biases,self.out_channels),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(ConvByMoveLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        return ch_convolve_by_moves(x,self.mask, self.conv_coeffs, self.biases)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], num_fields, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import InputLayer, Lambda, Flatten, Dense, merge\n",
    "# from keras.layers.merge import Concatenate\n",
    "# from keras import backend as K\n",
    "\n",
    "# player_pos_one_hot = Input(shape = [49, 2])\n",
    "# board_state = Input(shape=[49,1])\n",
    "# mask = board_state\n",
    "# #tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "# out = Concatenate()([board_state, player_pos_one_hot])\n",
    "\n",
    "# out= ConvByMoveLayer(3, mask)(out)\n",
    "# out = ConvByMoveLayer(5, mask)(out)\n",
    "# out = ConvByMoveLayer(7, mask)(out)\n",
    "# #out = Lambda(lambda x: get_random_index(*x), arguments = {batch_size,2})([out,player_pos])\n",
    "# out = Concatenate()([out, player_pos_one_hot])\n",
    "# out = Flatten()(out)\n",
    "# out = Dense(10, activation = 'relu')(out)\n",
    "# out = Dense(1)(out)\n",
    "\n",
    "# model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "# model.summary()\n",
    "# model.compile(optimizer = 'adam',  loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/ID_x2_1000ms/result_ID_x2_24.pickle', '../data/ID_x2_1000ms/result_ID_x2_22.pickle', '../data/ID_x2_1000ms/result_ID_x2_17.pickle', '../data/ID_x2_1000ms/result_ID_x2_4.pickle', '../data/ID_x2_1000ms/result_ID_x2_16.pickle', '../data/ID_x2_1000ms/result_ID_x2_8.pickle', '../data/ID_x2_1000ms/result_ID_x2_20.pickle', '../data/ID_x2_1000ms/result_ID_x2_13.pickle', '../data/ID_x2_1000ms/result_ID_x2_5.pickle', '../data/ID_x2_1000ms/result_ID_x2_2.pickle', '../data/ID_x2_1000ms/result_ID_x2_19.pickle', '../data/ID_x2_1000ms/result_ID_x2_11.pickle', '../data/ID_x2_1000ms/result_ID_x2_23.pickle', '../data/ID_x2_1000ms/result_ID_x2_10.pickle', '../data/ID_x2_1000ms/result_ID_x2_12.pickle', '../data/ID_x2_1000ms/result_ID_x2_18.pickle', '../data/ID_x2_1000ms/result_ID_x2_9.pickle', '../data/ID_x2_1000ms/result_ID_x2_6.pickle', '../data/ID_x2_1000ms/result_ID_x2_7.pickle', '../data/ID_x2_1000ms/result_ID_x2_21.pickle', '../data/ID_x2_1000ms/result_ID_x2_1.pickle', '../data/ID_x2_1000ms/result_ID_x2_15.pickle', '../data/ID_x2_1000ms/result_ID_x2_14.pickle', '../data/ID_x2_1000ms/result_ID_x2_3.pickle']\n",
      "['improved, two steps exact']\n",
      "[{'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), 'score': -19.0, 'move': (6, 3), 'pos': (18, 22), 'depth': 7, 'simple_score': -20.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
      "        1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), 'score': -16.0, 'move': (4, 4), 'pos': (27, 31), 'depth': 9, 'simple_score': -32.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
      "        1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), 'score': -12.0, 'move': (2, 3), 'pos': (32, 36), 'depth': 9, 'simple_score': 1.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': -11.0, 'move': (3, 5), 'pos': (23, 45), 'depth': 9, 'simple_score': 1.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': -8.0, 'move': (4, 3), 'pos': (38, 30), 'depth': 9, 'simple_score': -26.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
      "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': -6.0, 'move': (6, 2), 'pos': (25, 15), 'depth': 10, 'simple_score': -16.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': -5.0, 'move': (4, 1), 'pos': (20, 24), 'depth': 13, 'simple_score': -32.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
      "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': inf, 'move': (2, 2), 'pos': (11, 9), 'depth': 17, 'simple_score': -2.0}, {'allscores': None, 'game': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
      "        1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': inf, 'move': (1, 4), 'pos': (16, 14), 'depth': 11, 'simple_score': 1.0}, {'allscores': None, 'game': array([ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
      "        1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]), 'score': inf, 'move': (2, 6), 'pos': (29, 1), 'depth': 9, 'simple_score': -1.0}, {'allscores': None, 'game': array([ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
      "        1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.]), 'score': inf, 'move': (4, 5), 'pos': (44, 10), 'depth': 7, 'simple_score': -5.0}, {'allscores': None, 'game': array([ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
      "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.]), 'score': inf, 'move': (5, 3), 'pos': (39, 19), 'depth': 5, 'simple_score': -4.0}, {'allscores': None, 'game': array([ 1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
      "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.]), 'score': inf, 'move': (6, 1), 'pos': (26, 6), 'depth': 1, 'simple_score': 8.0}]\n"
     ]
    }
   ],
   "source": [
    "# load game simulation data\n",
    "import glob\n",
    "import sys\n",
    "#sys.path.append('./neural')\n",
    "from data_utils import load_simulation_data\n",
    "files = glob.glob('../data/ID_x2_1000ms/result_ID*.pickle')\n",
    "print(files)\n",
    "depths =load_simulation_data(files)\n",
    "keys = list(depths.keys())\n",
    "print(keys)\n",
    "games = depths[keys[0]]\n",
    "print(games[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def prepare_data_for_model(states, score_name = 'simple_score'):\n",
    "    y = np.array([state[score_name] for state in states])\n",
    "    board = np.array([list(state['game']) for state in states])\n",
    "    pos = np.array([list(state['pos']) for state in states])\n",
    "    print(board.shape,pos.shape, y.shape)\n",
    "    encoder = OneHotEncoder(49)\n",
    "    pos_oh = encoder.fit_transform(pos).toarray()\n",
    "\n",
    "    # now make sure they're the right shape\n",
    "    player_pos_one_hot_value = np.array( np.concatenate( [pos_oh[:,:49,None],pos_oh[:,49:,None]],2))\n",
    "    print(player_pos_one_hot_value[0])\n",
    "    board_full = np.array(np.reshape(board, [board.shape[0],49,1]))\n",
    "\n",
    "    return board_full, player_pos_one_hot_value, y[:,None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984694, 49) (984694, 2) (984694,)\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "states = [state for game in games for state in game] \n",
    "board_full, player_pos, y = prepare_data_for_model(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 49, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 49, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 49, 3)         0           input_2[0][0]                    \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_1 (ConvByMove (None, 49, 3)         309         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 49, 3)         12          conv_by_move_layer_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 49, 3)         0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_2 (ConvByMove (None, 49, 3)         309         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 49, 3)         12          conv_by_move_layer_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 49, 3)         0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_3 (ConvByMove (None, 49, 3)         309         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 49, 3)         0           conv_by_move_layer_1[0][0]       \n",
      "                                                                   conv_by_move_layer_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 49, 3)         0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 49, 5)         0           activation_3[0][0]               \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 245)           0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            2460        flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             11          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,422\n",
      "Trainable params: 3,410\n",
      "Non-trainable params: 12\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Activation\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "player_pos_one_hot = Input(shape = [49, 2])\n",
    "board_state = Input(shape=[49,1])\n",
    "mask = board_state\n",
    "num_features = 3\n",
    "\n",
    "def ResNetLayerFun(x, num_features = 3, mask = None):\n",
    "    tmp = BatchNormalization()(x)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = BatchNormalization()(tmp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    return Add()([x,tmp])\n",
    "\n",
    "#tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "out = Concatenate()([board_state, player_pos_one_hot])\n",
    "out = ConvByMoveLayer(num_features, mask)(out)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = Activation('relu')(out)\n",
    "out = Concatenate()([out, player_pos_one_hot])\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation = 'relu')(out)\n",
    "out = Dense(1)(out)\n",
    "\n",
    "model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam',  loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit([player_pos, board_full],y, batch_size = 256, epochs=5, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365201\n",
      "(365201, 49) (365201, 2) (365201,)\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's get all those games where tree search actually completed\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "complete_states = [state for game in games for state in game if state['score'] == float('inf') or state['score'] == float('-inf')]\n",
    "print(len(complete_states))\n",
    "board_full_c, player_pos_c, y_c = prepare_data_for_model(complete_states,'score')\n",
    "y_c[y_c==float('inf')] = 1\n",
    "y_c[y_c==float('-inf')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(set(list(np.reshape(y_c,[-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 49, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 49, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 49, 3)         0           input_4[0][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_4 (ConvByMove (None, 49, 8)         824         concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 49, 8)         32          conv_by_move_layer_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 49, 8)         0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_19 (ConvByMov (None, 49, 8)         2064        activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 49, 8)         32          conv_by_move_layer_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 49, 8)         0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_20 (ConvByMov (None, 49, 8)         2064        activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 49, 8)         0           conv_by_move_layer_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 49, 8)         0           conv_by_move_layer_4[0][0]       \n",
      "                                                                   dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 49, 8)         32          add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 49, 8)         0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_35 (ConvByMov (None, 49, 8)         2064        activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 49, 8)         32          conv_by_move_layer_35[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 49, 8)         0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_36 (ConvByMov (None, 49, 8)         2064        activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_36[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_17 (Add)                     (None, 49, 8)         0           add_9[0][0]                      \n",
      "                                                                   dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 49, 8)         32          add_17[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 49, 8)         0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_51 (ConvByMov (None, 49, 8)         2064        activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 49, 8)         32          conv_by_move_layer_51[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 49, 8)         0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_52 (ConvByMov (None, 49, 8)         2064        activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_52[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_25 (Add)                     (None, 49, 8)         0           add_17[0][0]                     \n",
      "                                                                   dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 49, 8)         32          add_25[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 49, 8)         0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_67 (ConvByMov (None, 49, 8)         2064        activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 49, 8)         32          conv_by_move_layer_67[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 49, 8)         0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_68 (ConvByMov (None, 49, 8)         2064        activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_68[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_33 (Add)                     (None, 49, 8)         0           add_25[0][0]                     \n",
      "                                                                   dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 49, 8)         32          add_33[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, 49, 8)         0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_83 (ConvByMov (None, 49, 8)         2064        activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 49, 8)         32          conv_by_move_layer_83[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, 49, 8)         0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_84 (ConvByMov (None, 49, 8)         2064        activation_83[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_84[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_41 (Add)                     (None, 49, 8)         0           add_33[0][0]                     \n",
      "                                                                   dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 49, 8)         32          add_41[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 49, 8)         0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_99 (ConvByMov (None, 49, 8)         2064        activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 49, 8)         32          conv_by_move_layer_99[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 49, 8)         0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_100 (ConvByMo (None, 49, 8)         2064        activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_100[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_49 (Add)                     (None, 49, 8)         0           add_41[0][0]                     \n",
      "                                                                   dropout_48[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 49, 8)         32          add_49[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 49, 8)         0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_115 (ConvByMo (None, 49, 8)         2064        activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 49, 8)         32          conv_by_move_layer_115[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 49, 8)         0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_116 (ConvByMo (None, 49, 8)         2064        activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_116[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_57 (Add)                     (None, 49, 8)         0           add_49[0][0]                     \n",
      "                                                                   dropout_56[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 49, 8)         32          add_57[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 49, 8)         0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_131 (ConvByMo (None, 49, 8)         2064        activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 49, 8)         32          conv_by_move_layer_131[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 49, 8)         0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_132 (ConvByMo (None, 49, 8)         2064        activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_132[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_65 (Add)                     (None, 49, 8)         0           add_57[0][0]                     \n",
      "                                                                   dropout_64[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 49, 8)         32          add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 49, 8)         0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_147 (ConvByMo (None, 49, 8)         2064        activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 49, 8)         32          conv_by_move_layer_147[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 49, 8)         0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_148 (ConvByMo (None, 49, 8)         2064        activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_148[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_73 (Add)                     (None, 49, 8)         0           add_65[0][0]                     \n",
      "                                                                   dropout_72[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 49, 8)         32          add_73[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 49, 8)         0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_163 (ConvByMo (None, 49, 8)         2064        activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 49, 8)         32          conv_by_move_layer_163[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 49, 8)         0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_164 (ConvByMo (None, 49, 8)         2064        activation_163[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_164[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_81 (Add)                     (None, 49, 8)         0           add_73[0][0]                     \n",
      "                                                                   dropout_80[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 49, 8)         32          add_81[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 49, 8)         0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_179 (ConvByMo (None, 49, 8)         2064        activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 49, 8)         32          conv_by_move_layer_179[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 49, 8)         0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_180 (ConvByMo (None, 49, 8)         2064        activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_180[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_89 (Add)                     (None, 49, 8)         0           add_81[0][0]                     \n",
      "                                                                   dropout_88[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchNo (None, 49, 8)         32          add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_194 (Activation)      (None, 49, 8)         0           batch_normalization_193[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_195 (ConvByMo (None, 49, 8)         2064        activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchNo (None, 49, 8)         32          conv_by_move_layer_195[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_195 (Activation)      (None, 49, 8)         0           batch_normalization_194[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_196 (ConvByMo (None, 49, 8)         2064        activation_195[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)             (None, 49, 8)         0           conv_by_move_layer_196[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_97 (Add)                     (None, 49, 8)         0           add_89[0][0]                     \n",
      "                                                                   dropout_96[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchNo (None, 49, 8)         32          add_97[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_210 (Activation)      (None, 49, 8)         0           batch_normalization_209[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_211 (ConvByMo (None, 49, 8)         2064        activation_210[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchNo (None, 49, 8)         32          conv_by_move_layer_211[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_211 (Activation)      (None, 49, 8)         0           batch_normalization_210[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_212 (ConvByMo (None, 49, 8)         2064        activation_211[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_212[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_105 (Add)                    (None, 49, 8)         0           add_97[0][0]                     \n",
      "                                                                   dropout_104[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchNo (None, 49, 8)         32          add_105[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_226 (Activation)      (None, 49, 8)         0           batch_normalization_225[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_227 (ConvByMo (None, 49, 8)         2064        activation_226[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchNo (None, 49, 8)         32          conv_by_move_layer_227[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_227 (Activation)      (None, 49, 8)         0           batch_normalization_226[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_228 (ConvByMo (None, 49, 8)         2064        activation_227[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_228[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_113 (Add)                    (None, 49, 8)         0           add_105[0][0]                    \n",
      "                                                                   dropout_112[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchNo (None, 49, 8)         32          add_113[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_242 (Activation)      (None, 49, 8)         0           batch_normalization_241[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_243 (ConvByMo (None, 49, 8)         2064        activation_242[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchNo (None, 49, 8)         32          conv_by_move_layer_243[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_243 (Activation)      (None, 49, 8)         0           batch_normalization_242[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_244 (ConvByMo (None, 49, 8)         2064        activation_243[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_244[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_121 (Add)                    (None, 49, 8)         0           add_113[0][0]                    \n",
      "                                                                   dropout_120[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchNo (None, 49, 8)         32          add_121[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_258 (Activation)      (None, 49, 8)         0           batch_normalization_257[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_259 (ConvByMo (None, 49, 8)         2064        activation_258[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchNo (None, 49, 8)         32          conv_by_move_layer_259[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_259 (Activation)      (None, 49, 8)         0           batch_normalization_258[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_260 (ConvByMo (None, 49, 8)         2064        activation_259[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_260[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_129 (Add)                    (None, 49, 8)         0           add_121[0][0]                    \n",
      "                                                                   dropout_128[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchNo (None, 49, 8)         32          add_129[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_274 (Activation)      (None, 49, 8)         0           batch_normalization_273[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_275 (ConvByMo (None, 49, 8)         2064        activation_274[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchNo (None, 49, 8)         32          conv_by_move_layer_275[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_275 (Activation)      (None, 49, 8)         0           batch_normalization_274[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_276 (ConvByMo (None, 49, 8)         2064        activation_275[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_276[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_137 (Add)                    (None, 49, 8)         0           add_129[0][0]                    \n",
      "                                                                   dropout_136[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchNo (None, 49, 8)         32          add_137[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_290 (Activation)      (None, 49, 8)         0           batch_normalization_289[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_291 (ConvByMo (None, 49, 8)         2064        activation_290[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchNo (None, 49, 8)         32          conv_by_move_layer_291[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_291 (Activation)      (None, 49, 8)         0           batch_normalization_290[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_292 (ConvByMo (None, 49, 8)         2064        activation_291[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_292[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_145 (Add)                    (None, 49, 8)         0           add_137[0][0]                    \n",
      "                                                                   dropout_144[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchNo (None, 49, 8)         32          add_145[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_306 (Activation)      (None, 49, 8)         0           batch_normalization_305[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_307 (ConvByMo (None, 49, 8)         2064        activation_306[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchNo (None, 49, 8)         32          conv_by_move_layer_307[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_307 (Activation)      (None, 49, 8)         0           batch_normalization_306[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_308 (ConvByMo (None, 49, 8)         2064        activation_307[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_308[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_153 (Add)                    (None, 49, 8)         0           add_145[0][0]                    \n",
      "                                                                   dropout_152[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchNo (None, 49, 8)         32          add_153[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_322 (Activation)      (None, 49, 8)         0           batch_normalization_321[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_323 (ConvByMo (None, 49, 8)         2064        activation_322[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchNo (None, 49, 8)         32          conv_by_move_layer_323[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_323 (Activation)      (None, 49, 8)         0           batch_normalization_322[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_324 (ConvByMo (None, 49, 8)         2064        activation_323[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_324[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_161 (Add)                    (None, 49, 8)         0           add_153[0][0]                    \n",
      "                                                                   dropout_160[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchNo (None, 49, 8)         32          add_161[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_338 (Activation)      (None, 49, 8)         0           batch_normalization_337[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_339 (ConvByMo (None, 49, 8)         2064        activation_338[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchNo (None, 49, 8)         32          conv_by_move_layer_339[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_339 (Activation)      (None, 49, 8)         0           batch_normalization_338[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_340 (ConvByMo (None, 49, 8)         2064        activation_339[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_340[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_169 (Add)                    (None, 49, 8)         0           add_161[0][0]                    \n",
      "                                                                   dropout_168[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchNo (None, 49, 8)         32          add_169[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_354 (Activation)      (None, 49, 8)         0           batch_normalization_353[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_355 (ConvByMo (None, 49, 8)         2064        activation_354[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchNo (None, 49, 8)         32          conv_by_move_layer_355[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_355 (Activation)      (None, 49, 8)         0           batch_normalization_354[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_356 (ConvByMo (None, 49, 8)         2064        activation_355[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_356[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_177 (Add)                    (None, 49, 8)         0           add_169[0][0]                    \n",
      "                                                                   dropout_176[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchNo (None, 49, 8)         32          add_177[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_370 (Activation)      (None, 49, 8)         0           batch_normalization_369[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_371 (ConvByMo (None, 49, 8)         2064        activation_370[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchNo (None, 49, 8)         32          conv_by_move_layer_371[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_371 (Activation)      (None, 49, 8)         0           batch_normalization_370[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_372 (ConvByMo (None, 49, 8)         2064        activation_371[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_372[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_185 (Add)                    (None, 49, 8)         0           add_177[0][0]                    \n",
      "                                                                   dropout_184[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchNo (None, 49, 8)         32          add_185[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_386 (Activation)      (None, 49, 8)         0           batch_normalization_385[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_387 (ConvByMo (None, 49, 8)         2064        activation_386[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchNo (None, 49, 8)         32          conv_by_move_layer_387[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_387 (Activation)      (None, 49, 8)         0           batch_normalization_386[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_388 (ConvByMo (None, 49, 8)         2064        activation_387[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_192 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_388[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_193 (Add)                    (None, 49, 8)         0           add_185[0][0]                    \n",
      "                                                                   dropout_192[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchNo (None, 49, 8)         32          add_193[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_402 (Activation)      (None, 49, 8)         0           batch_normalization_401[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_403 (ConvByMo (None, 49, 8)         2064        activation_402[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchNo (None, 49, 8)         32          conv_by_move_layer_403[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_403 (Activation)      (None, 49, 8)         0           batch_normalization_402[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_404 (ConvByMo (None, 49, 8)         2064        activation_403[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_200 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_404[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_201 (Add)                    (None, 49, 8)         0           add_193[0][0]                    \n",
      "                                                                   dropout_200[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchNo (None, 49, 8)         32          add_201[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_418 (Activation)      (None, 49, 8)         0           batch_normalization_417[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_419 (ConvByMo (None, 49, 8)         2064        activation_418[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchNo (None, 49, 8)         32          conv_by_move_layer_419[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_419 (Activation)      (None, 49, 8)         0           batch_normalization_418[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_420 (ConvByMo (None, 49, 8)         2064        activation_419[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_208 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_420[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_209 (Add)                    (None, 49, 8)         0           add_201[0][0]                    \n",
      "                                                                   dropout_208[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchNo (None, 49, 8)         32          add_209[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_434 (Activation)      (None, 49, 8)         0           batch_normalization_433[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_435 (ConvByMo (None, 49, 8)         2064        activation_434[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchNo (None, 49, 8)         32          conv_by_move_layer_435[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_435 (Activation)      (None, 49, 8)         0           batch_normalization_434[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_436 (ConvByMo (None, 49, 8)         2064        activation_435[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_216 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_436[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_217 (Add)                    (None, 49, 8)         0           add_209[0][0]                    \n",
      "                                                                   dropout_216[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchNo (None, 49, 8)         32          add_217[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_450 (Activation)      (None, 49, 8)         0           batch_normalization_449[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_451 (ConvByMo (None, 49, 8)         2064        activation_450[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchNo (None, 49, 8)         32          conv_by_move_layer_451[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_451 (Activation)      (None, 49, 8)         0           batch_normalization_450[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_452 (ConvByMo (None, 49, 8)         2064        activation_451[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_224 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_452[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_225 (Add)                    (None, 49, 8)         0           add_217[0][0]                    \n",
      "                                                                   dropout_224[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchNo (None, 49, 8)         32          add_225[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_466 (Activation)      (None, 49, 8)         0           batch_normalization_465[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_467 (ConvByMo (None, 49, 8)         2064        activation_466[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchNo (None, 49, 8)         32          conv_by_move_layer_467[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_467 (Activation)      (None, 49, 8)         0           batch_normalization_466[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_468 (ConvByMo (None, 49, 8)         2064        activation_467[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_232 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_468[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_233 (Add)                    (None, 49, 8)         0           add_225[0][0]                    \n",
      "                                                                   dropout_232[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchNo (None, 49, 8)         32          add_233[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_482 (Activation)      (None, 49, 8)         0           batch_normalization_481[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_483 (ConvByMo (None, 49, 8)         2064        activation_482[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchNo (None, 49, 8)         32          conv_by_move_layer_483[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_483 (Activation)      (None, 49, 8)         0           batch_normalization_482[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_484 (ConvByMo (None, 49, 8)         2064        activation_483[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_240 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_484[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_241 (Add)                    (None, 49, 8)         0           add_233[0][0]                    \n",
      "                                                                   dropout_240[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchNo (None, 49, 8)         32          add_241[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_498 (Activation)      (None, 49, 8)         0           batch_normalization_497[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_499 (ConvByMo (None, 49, 8)         2064        activation_498[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchNo (None, 49, 8)         32          conv_by_move_layer_499[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_499 (Activation)      (None, 49, 8)         0           batch_normalization_498[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_500 (ConvByMo (None, 49, 8)         2064        activation_499[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_248 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_500[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_249 (Add)                    (None, 49, 8)         0           add_241[0][0]                    \n",
      "                                                                   dropout_248[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchNo (None, 49, 8)         32          add_249[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_514 (Activation)      (None, 49, 8)         0           batch_normalization_513[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_515 (ConvByMo (None, 49, 8)         2064        activation_514[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchNo (None, 49, 8)         32          conv_by_move_layer_515[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_515 (Activation)      (None, 49, 8)         0           batch_normalization_514[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv_by_move_layer_516 (ConvByMo (None, 49, 8)         2064        activation_515[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_256 (Dropout)            (None, 49, 8)         0           conv_by_move_layer_516[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "add_257 (Add)                    (None, 49, 8)         0           add_249[0][0]                    \n",
      "                                                                   dropout_256[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_516 (Activation)      (None, 49, 8)         0           add_257[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 49, 10)        0           activation_516[0][0]             \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 490)           0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            4910        flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             22          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 139,900\n",
      "Trainable params: 138,876\n",
      "Non-trainable params: 1,024\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Activation, Dropout\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "player_pos_one_hot = Input(shape = [49, 2])\n",
    "board_state = Input(shape=[49,1])\n",
    "mask = board_state\n",
    "num_features = 8\n",
    "num_blocks = 8\n",
    "num_res_modules = 32\n",
    "drop_rate = 0.2\n",
    "\n",
    "def BlockFun(x, num_features = 3, mask = None):\n",
    "    tmp = BatchNormalization()(x)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = BatchNormalization()(tmp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = Dropout(drop_rate)(tmp)\n",
    "    return tmp\n",
    "\n",
    "def ResNetLayerFun1(x, num_features = 3, num_blocks=1, mask = None):\n",
    "    tmp = x\n",
    "    for _ in range(num_blocks):\n",
    "        tmp = Add()([x,BlockFun(x, num_features, mask)])\n",
    "    return tmp\n",
    "\n",
    "def ResNetLayerFun2(x, num_features = 3, num_blocks=1, mask = None):\n",
    "    tmp = [x]\n",
    "    for _ in range(num_blocks):\n",
    "        tmp.append(BlockFun(x, num_features, mask))\n",
    "    return Concatenate()(tmp)\n",
    "    \n",
    "    \n",
    "\n",
    "#tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "out = Concatenate()([board_state, player_pos_one_hot])\n",
    "out = ConvByMoveLayer(num_features, mask)(out)\n",
    "for _ in range(num_res_modules):\n",
    "    out = ResNetLayerFun1(out, num_features, num_blocks, mask)\n",
    "out = Activation('relu')(out)\n",
    "out = Concatenate()([out, player_pos_one_hot])\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation = 'relu')(out)\n",
    "out = Dense(2, activation = 'softmax')(out)\n",
    "\n",
    "deep_model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "deep_model.summary()\n",
    "deep_model.compile(optimizer = 'adam',  loss='categorical_crossentropy', metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 328680 samples, validate on 36521 samples\n",
      "Epoch 1/10\n",
      "328680/328680 [==============================] - 1162s - loss: 0.3546 - acc: 0.8436 - val_loss: 0.2543 - val_acc: 0.9069\n",
      "Epoch 2/10\n",
      "328680/328680 [==============================] - 1131s - loss: 0.2477 - acc: 0.9090 - val_loss: 0.2395 - val_acc: 0.9105\n",
      "Epoch 3/10\n",
      "328680/328680 [==============================] - 1122s - loss: 0.2357 - acc: 0.9124 - val_loss: 0.2304 - val_acc: 0.9134\n",
      "Epoch 4/10\n",
      "328680/328680 [==============================] - 1125s - loss: 0.2293 - acc: 0.9144 - val_loss: 0.2239 - val_acc: 0.9177\n",
      "Epoch 5/10\n",
      "328680/328680 [==============================] - 1119s - loss: 0.2236 - acc: 0.9162 - val_loss: 0.2189 - val_acc: 0.9178\n",
      "Epoch 6/10\n",
      "328680/328680 [==============================] - 1126s - loss: 0.2206 - acc: 0.9173 - val_loss: 0.2178 - val_acc: 0.9191\n",
      "Epoch 7/10\n",
      "328680/328680 [==============================] - 1118s - loss: 0.2164 - acc: 0.9187 - val_loss: 0.2147 - val_acc: 0.9205\n",
      "Epoch 8/10\n",
      "328680/328680 [==============================] - 1125s - loss: 0.2133 - acc: 0.9199 - val_loss: 0.2113 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "328680/328680 [==============================] - 1129s - loss: 0.2114 - acc: 0.9205 - val_loss: 0.2164 - val_acc: 0.9192\n",
      "Epoch 10/10\n",
      "328680/328680 [==============================] - 1131s - loss: 0.2088 - acc: 0.9210 - val_loss: 0.2148 - val_acc: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb21fe0cd68>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "deep_model.fit([player_pos_c, board_full_c],to_categorical(y_c, num_classes=2), batch_size = 64, epochs=10, verbose =1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "apply_move() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-60a1c1e31000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mother_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mgame1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mgame2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mgame3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: apply_move() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from copy import copy\n",
    "\n",
    "SimpleGame = namedtuple(\"Simple_game\", [\"moving_player_pos\",\"other_player_pos\", \"board\"])\n",
    "move_dict = generate_all_moves_by_index()\n",
    "\n",
    "def get_legal_moves(game):\n",
    "    if game.moving_player_pos is None:\n",
    "        return [m for m in range(49) if game.board[m] == 1]\n",
    "    else:\n",
    "        moves = move_dict[game.moving_player_pos]\n",
    "        return [m for m in moves if game.board[m] ==1 ]\n",
    "\n",
    "def apply_move(game, move):\n",
    "    if not move in get_legal_moves(game):\n",
    "        raise ValueError('Illegal move!')\n",
    "    new_board = copy(game.board)\n",
    "    new_board[move] = 0\n",
    "    other_pos = move\n",
    "    moving_pos = game.other_player_pos\n",
    "    return SimpleGame(moving_pos, other_pos, new_board)\n",
    "    \n",
    "board = np.ones(49)\n",
    "board.sum()\n",
    "my_pos = None\n",
    "other_pos = None\n",
    "game = SimpleGame(my_pos, other_pos, board)\n",
    "game1 = apply_move(game, 0, move_dict)\n",
    "game2 = apply_move(game1, 1, move_dict)\n",
    "game3 = apply_move(game2, 14, move_dict)\n",
    "print(game3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort all games by number of moves. \n",
    "\n",
    "\n",
    "states_by_num_moves = [[] for _ in range(49)]\n",
    "\n",
    "for state in states:\n",
    "    moves_made = 49 - state['game'].sum()\n",
    "    states_by_num_moves[int(moves_made)].append(state)\n",
    "    \n",
    "for n in range(49):\n",
    "    print(n,len(states_by_num_moves[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iteratively populate all non-+-inf values in layer n from evaluating model in layer n+1, then include these into the fitting set\n",
    "# after each pass, refresh the values for earlier layers\n",
    "\n",
    "prepared_data = [None for _ in range(49)]\n",
    "for n in range(2,49):\n",
    "    prepared_data[n] = prepare_data_for_model( states_by_num_moves[n],'score') # board, player_pos, score\n",
    "    \n",
    "# TODO: is my position always first in those dumps???\n",
    "    \n",
    "def recursively_fill_scores(board, player_pos, scores, eval_fun):\n",
    "    new_scores = scores.copy()\n",
    "    new_scores[scores == float('inf')] =1 \n",
    "    new_scores[scores == float('-inf')] = 0\n",
    "    for n, score in enumerate(scores):\n",
    "        if score not in [float('inf'), float('-inf')]:\n",
    "            new_scores[n] = get_recursive_score(board[n], player_pos[n], eval_fun)\n",
    "            \n",
    "def get_recursive_score(board, player_pos, eval_fun):\n",
    "    this_game = SimpleGame(board, player_pos[0], player_pos[1])\n",
    "    moves = get_legal_moves(this_game)\n",
    "    vals = np.array([1 - eval_fun(apply_move(this_game, move)) for move in moves])\n",
    "    return vals.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
