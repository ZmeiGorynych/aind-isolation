{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# generate the symmetry-corrected indices for move-based convolution\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from neural import generate_all_moves_by_index, move_convolution_indices\n",
    "#generate_all_moves_by_index()\n",
    "all_inds, num_coeffs = move_convolution_indices()\n",
    "num_coeffs -= 10 # the first 10 in the above function are biases, don't need them\n",
    "num_biases = 10\n",
    "print(num_coeffs)\n",
    "num_fields = 7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the coefficient generation logic the naive way\n",
    "cell = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[  0.   0.  39.   0.  39.   0.   0.]\n",
      " [  0.  38.   0.   0.   0.  38.   0.]\n",
      " [  0.   0.   0.   9.   0.   0.   0.]\n",
      " [  0.  36.   0.   0.   0.  36.   0.]\n",
      " [  0.   0.  37.   0.  37.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "from neural import to_pair\n",
    "cell = cell+1\n",
    "tmp = all_inds[cell]\n",
    "a = np.zeros([7,7])\n",
    "for (ind, coeff) in tmp[1:]:\n",
    "    pair = to_pair(ind)\n",
    "    a[pair[0],pair[1]] = coeff - 9\n",
    "\n",
    "print(to_pair(cell))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_to_board(vec):\n",
    "    board = np.reshape(vec,[7,7])\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert that dict into a 3d-tensor,\n",
    "# [in_field, out_field, coeff_ind]\n",
    "\n",
    "conv_map = np.zeros([num_fields, num_fields, num_coeffs])\n",
    "bias_map = np.zeros([num_fields, num_biases])\n",
    "for cell in range(num_fields):\n",
    "    tmp = all_inds[cell]\n",
    "    bias_map[cell, tmp[0][1]] = 1\n",
    "    #print(cell,tmp[0])\n",
    "    for (ind, coeff) in tmp[1:]:\n",
    "        pair = to_pair(ind)\n",
    "        conv_map[cell, ind, coeff-10] = 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's do the convolution in Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_mapping = tf.constant(conv_map,dtype=tf.float32, name = 'conv_mapping')  \n",
    "bias_mapping = tf.constant(bias_map,dtype=tf.float32, name = 'bias_mapping')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolve_by_moves(in_fields, mask, this_conv_coeffs, biases): \n",
    "    '''\n",
    "    in_fields is a batch of tensors [batch_size, num_fields, num_channels]\n",
    "    mask is a tensor of 0s and 1s [num_fields]\n",
    "    so conv_coeffs must have size [num_coeffs, channels_in, channels_out]\n",
    "    '''\n",
    "    \n",
    "    tmp = tf.tensordot(conv_mapping, this_conv_coeffs, [[2],[0]])\n",
    "    #print(sess.run([tf.shape(tmp), tf.shape(in_fields)]))\n",
    "    tmp2 = tf.matmul(tf.cast(in_fields,tf.float32), tmp)\n",
    "    out = tf.multiply(tmp2, tf.cast(mask,tf.float32))\n",
    "    # TODO: biases must also be symmetry-corrected!\n",
    "    return out + biases\n",
    "\n",
    "# this wrapper just defines the Variables, to be replaced by a Keras wrapper\n",
    " # approx avg number of inputs is 6 or so, so normalize init weights accordingly\n",
    "def convolve_by_moves_with_coeffs(in_fields, mask, \n",
    "                      wgt_init = tf.truncated_normal(shape=[num_coeffs],stddev = 1/2.5,\n",
    "                                                     dtype=tf.float32)):\n",
    "    this_conv_coeffs = tf.Variable(wgt_init)\n",
    "    # TODO: biases must also be symmetry-corrected!\n",
    "    biases = tf.Variable(np.zeros(num_fields), dtype = tf.float32) \n",
    "    return convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases, sess=None): \n",
    "    '''\n",
    "    in_fields is a batch of tensors [batch_size, num_fields, num_channels]\n",
    "    mask is a tensor of 0s and 1s [num_fields]\n",
    "    so conv_coeffs must have size [num_coeffs, channels_in, channels_out]\n",
    "    '''\n",
    "    input_dim = in_fields.get_shape().as_list()\n",
    "    if len(input_dim) == 2: # just batch and fields\n",
    "        in_fields = tf.expand_dims(in_fields,2) # add the channel dimension\n",
    "    # inputs conv_mapping[i,j,k], this_conv_coeffs[k,m,l], output tmp[i,j,m,l]\n",
    "    tmp = tf.tensordot(conv_mapping, this_conv_coeffs, [[2],[0]]) \n",
    "    #print(sess.run([tf.shape(tmp), tf.shape(in_fields)]))\n",
    "    # in_fields[b,j,m], output is tmp2[b,i,l]\n",
    "    tmp2 = tf.tensordot(tf.cast(in_fields,tf.float32), tmp, [[1,2],[1,2]])\n",
    "    \n",
    "    # bias_mapping[i,k], biases[k,l], bias_term should be [b,i,l] but in this line just get [i,l]: \n",
    "    tmp_bias = tf.tensordot(bias_mapping, biases,[[1],[0]])\n",
    "\n",
    "    out = tmp2 + tf.expand_dims(tmp_bias, 0) # use broadcasting to add biases to each batch\n",
    "    \n",
    "    if mask is not None:\n",
    "        # mask is [b,i], batches x num_fields, need to apply to all channels of output - use broadcasting\n",
    "        if len(mask.get_shape()) == 2:\n",
    "            mask = tf.expand_dims(mask, 2)\n",
    "        out = tf.multiply(out, tf.cast(mask,tf.float32))\n",
    "    return out\n",
    "\n",
    "# this wrapper just defines the Variables, to be replaced by a Keras wrapper\n",
    " # approx avg number of inputs is 6 or so, so normalize init weights accordingly\n",
    "def ch_convolve_by_moves_with_coeffs(in_fields, mask, out_channels, wgt_init = None, sess=None):\n",
    "    in_channels = in_fields.get_shape().as_list()[-1]\n",
    "    #print(sess.run(tf.shape(in_fields)[-1]))\n",
    "    #print(in_fields.get_shape().as_list())\n",
    "    if not wgt_init:\n",
    "        wgt_init = tf.truncated_normal(shape=[num_coeffs,in_channels, out_channels],stddev = 1/2.5,\n",
    "                                                     dtype=tf.float32)\n",
    "    this_conv_coeffs = tf.Variable(wgt_init)\n",
    "    \n",
    "    biases = tf.Variable(np.zeros([num_biases, out_channels]), dtype = tf.float32)\n",
    "    return ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Show all coefficient indices\n",
    "# with tf.Session() as sess:\n",
    "#     for ind in range(49):\n",
    "#         in_fields_np = np.zeros([2,num_fields])\n",
    "#         in_fields_np[0,3] = 1\n",
    "#         in_fields_np[0,5] = 1\n",
    "#         in_fields_np[1,ind] = 1\n",
    "#         in_fields = tf.constant(np.array(in_fields_np))\n",
    "\n",
    "#         mask = tf.constant(np.ones(in_fields_np[0].shape))\n",
    "#         out = convolve_by_moves(in_fields, mask, np.ones(num_coeffs))\n",
    "#         out_2 = convolve_by_moves(out, mask, np.ones(num_coeffs))\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         print(vec_to_board(sess.run(out_2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_index(x, ind, batch_size, sess = None):\n",
    "    '''\n",
    "    x: [batch_size, num_fields]\n",
    "    ind: [batch_size,2] # 2 random indexes (me and opponent) I want to grab in the corresponding row\n",
    "    '''\n",
    "    #\n",
    "    batch_ind = tf.constant(np.array(range(batch_size))[:,None])\n",
    "    batch_nums = tf.cast(batch_ind, tf.int32)\n",
    "    ind =tf.cast(ind, tf.int32)\n",
    "    ind1 = tf.slice(ind,[0,0],[-1,1])\n",
    "    ind2 = tf.slice(ind,[0,1],[-1,1])\n",
    "    ind_ext1 = tf.concat([batch_nums,ind1],1)\n",
    "    ind_ext2 = tf.concat([batch_nums, ind2],1)\n",
    "    out1 =tf.expand_dims(tf.gather_nd(x,ind_ext1),2)\n",
    "    out2 =tf.expand_dims(tf.gather_nd(x,ind_ext2),2)\n",
    "    out = tf.concat([out1,out2],2)\n",
    "    print(sess.run(tf.shape(out)))\n",
    "    return out\n",
    "\n",
    "def conv_stack(inputs, num_layers, sess = None):\n",
    "    '''\n",
    "    in_fields: [batch_size, num_fields]\n",
    "    num_layers: int\n",
    "    my_pos: [batch_size, 1]\n",
    "    other_pos: [batch_size, 1]\n",
    "    '''\n",
    "    in_fields = tf.slice(inputs,[0,0],[-1,num_fields])\n",
    "    player_pos = tf.slice(inputs,[0,num_fields],[-1,2])\n",
    "#     print(sess.run(in_fields))\n",
    "#     print(sess.run(tf.shape(my_pos)))\n",
    "#     print(sess.run(tf.shape(other_pos)))\n",
    "    mask = in_fields\n",
    "    out = tf.expand_dims(in_fields,2) # add the channel dimension\n",
    "    for _ in range(num_layers):\n",
    "        out = ch_convolve_by_moves_with_coeffs(out, in_fields, 3, sess=sess)\n",
    "        \n",
    "    player_wgt = tf.Variable(tf.truncated_normal(shape =[1,2],dtype=tf.float32))\n",
    "    #other_wgt = tf.Variable(tf.truncated_normal(shape =[1],dtype=tf.float32))\n",
    "    \n",
    "    batch_size = out.shape[0]\n",
    "    return player_wgt*get_random_index(out, player_pos, batch_size,sess) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2]\n",
      "[[[-33.07406998   6.52392483]\n",
      "  [-51.27360916   9.89130402]\n",
      "  [-22.37611198  -0.50702095]]\n",
      "\n",
      " [[-36.80244064   3.76258183]\n",
      "  [-57.66779709   9.19933701]\n",
      "  [-24.11888885   1.77019632]]]\n"
     ]
    }
   ],
   "source": [
    "# try calling conv_stack\n",
    "with tf.Session() as sess:\n",
    "    in_fields_np = np.ones([2,num_fields])\n",
    "    in_fields_np[0,3] = 0\n",
    "    in_fields_np[0,5] = 0\n",
    "    my_pos = np.array([24, 24])\n",
    "    other_pos =  np.array([33,33])\n",
    "    inputs_np = np.concatenate([in_fields_np, my_pos[:,None], other_pos[:,None]],\n",
    "                              1)\n",
    "    #print(inputs_np.shape)\n",
    "    inputs =tf.constant(inputs_np)# tf.placeholder(shape =[None, num_fields+2], dtype = tf.float32) #\n",
    "    #print(sess.run(inputs))\n",
    "    out = conv_stack(inputs, 5,sess)\n",
    "    \n",
    "    dummy = np.array([50,50])[:,None]\n",
    "    #print(sess.run(get_random_index(inputs, tf.constant(dummy))))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    stack_result = sess.run(out)#, feed_dict={inputs:inputs_np})\n",
    "    print(stack_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create a Keras model from the above, to simplify fitting: just using Lambda fails as tf.Variables are not recognized by Keras\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Input, Lambda\n",
    "\n",
    "# #model_in = tf.placeholder(tf.float32, shape = (None, 51))\n",
    "# #model_out = conv_stack(model_in, 5)\n",
    "# my_fun = Lambda(lambda x: conv_stack(x, 5))\n",
    "# #my_model = Model(Input(tensor = model_in), outputs = my_fun(model_in))\n",
    "# my_input = Input(shape = [51])\n",
    "# my_output = my_fun(my_input)\n",
    "# my_model = Model(inputs = my_input, outputs = my_output)\n",
    "# my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a4e4434a42ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     return ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTruncatedNormal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprojector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfactorization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_editor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\contrib\\factorization\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclustering_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorization_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgmm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgmm_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\contrib\\factorization\\python\\ops\\gmm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheckpoint_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_fn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\contrib\\learn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m                     'utils', 'graph_actions']\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m \u001b[0mremove_undocumented\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_allowed_symbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\util\\all_util.py\u001b[0m in \u001b[0;36mremove_undocumented\u001b[1;34m(module_name, allowed_exception_list, doc_string_modules)\u001b[0m\n\u001b[0;32m    101\u001b[0m   \"\"\"\n\u001b[0;32m    102\u001b[0m   \u001b[0mcurrent_symbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m   \u001b[0mshould_have\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_string_modules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m   \u001b[0mshould_have\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mallowed_exception_list\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mextra_symbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_symbols\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshould_have\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\util\\all_util.py\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(module_name, doc_string_modules)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mdoc_string_modules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m   cur_members = set([name for name, _\n\u001b[1;32m---> 50\u001b[1;33m                      in _tf_inspect.getmembers(_sys.modules[module_name])])\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py\u001b[0m in \u001b[0;36mgetmembers\u001b[1;34m(object, predicate)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetmembers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;34m\"\"\"TFDecorator-aware replacement for inspect.getmembers.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetmembers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Egor\\Anaconda2\\envs\\aind\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetmembers\u001b[1;34m(object, predicate)\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;31m# handle the duplicate key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmro\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# So let's create a custom Keras layer instead\n",
    "\n",
    "# def ch_convolve_by_moves_with_coeffs(in_fields, mask, out_channels):\n",
    "#     in_channels = in_fields.get_shape().as_list()[-1]\n",
    "#     wgt_init = tf.truncated_normal(shape=[num_coeffs,in_channels, out_channels],\n",
    "#                                     stddev = 1/2.5,\n",
    "#                                     dtype=tf.float32)\n",
    "#     this_conv_coeffs = tf.Variable(wgt_init)\n",
    "#     biases = tf.Variable(np.zeros([num_biases, out_channels]), dtype = tf.float32)\n",
    "#     return ch_convolve_by_moves(in_fields, mask, this_conv_coeffs, biases)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.initializers import TruncatedNormal\n",
    "import numpy as np\n",
    "\n",
    "class ConvByMoveLayer(Layer):\n",
    "\n",
    "    def __init__(self, out_channels, mask = None, **kwargs):\n",
    "        self.out_channels = out_channels\n",
    "        self.mask = mask\n",
    "        super(ConvByMoveLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        if len(input_shape)==2:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = input_shape[2]\n",
    "            \n",
    "        init_std = 1/(3*np.sqrt(in_channels*self.out_channels))\n",
    "            \n",
    "        self.conv_coeffs = self.add_weight(name='conv_coeffs', \n",
    "                                      shape=(num_coeffs,in_channels, self.out_channels),\n",
    "                                      initializer=TruncatedNormal(stddev = init_std),\n",
    "                                      trainable=True)\n",
    "        #print((num_coeffs, in_channels, self.out_channels))\n",
    "        self.biases = self.add_weight(name='biases', \n",
    "                                      shape=(num_biases,self.out_channels),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(ConvByMoveLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        return ch_convolve_by_moves(x,self.mask, self.conv_coeffs, self.biases)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], num_fields, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import InputLayer, Lambda, Flatten, Dense, merge\n",
    "# from keras.layers.merge import Concatenate\n",
    "# from keras import backend as K\n",
    "\n",
    "# player_pos_one_hot = Input(shape = [49, 2])\n",
    "# board_state = Input(shape=[49,1])\n",
    "# mask = board_state\n",
    "# #tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "# out = Concatenate()([board_state, player_pos_one_hot])\n",
    "\n",
    "# out= ConvByMoveLayer(3, mask)(out)\n",
    "# out = ConvByMoveLayer(5, mask)(out)\n",
    "# out = ConvByMoveLayer(7, mask)(out)\n",
    "# #out = Lambda(lambda x: get_random_index(*x), arguments = {batch_size,2})([out,player_pos])\n",
    "# out = Concatenate()([out, player_pos_one_hot])\n",
    "# out = Flatten()(out)\n",
    "# out = Dense(10, activation = 'relu')(out)\n",
    "# out = Dense(1)(out)\n",
    "\n",
    "# model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "# model.summary()\n",
    "# model.compile(optimizer = 'adam',  loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load game simulation data\n",
    "import glob\n",
    "import sys\n",
    "#sys.path.append('./neural')\n",
    "from data_utils import load_simulation_data\n",
    "files = glob.glob('../data/ID_x2_1000ms/result_ID*.pickle')\n",
    "print(files)\n",
    "depths =load_simulation_data(files)\n",
    "keys = list(depths.keys())\n",
    "print(keys)\n",
    "games = depths[keys[0]]\n",
    "print(games[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def prepare_data_for_model(states, score_name = 'simple_score'):\n",
    "    y = np.array([state[score_name] for state in states])\n",
    "    board = np.array([list(state['game']) for state in states])\n",
    "    pos = np.array([list(state['pos']) for state in states])\n",
    "    print(board.shape,pos.shape, y.shape)\n",
    "    encoder = OneHotEncoder(49)\n",
    "    pos_oh = encoder.fit_transform(pos).toarray()\n",
    "\n",
    "    # now make sure they're the right shape\n",
    "    player_pos_one_hot_value = np.array( np.concatenate( [pos_oh[:,:49,None],pos_oh[:,49:,None]],2))\n",
    "    print(player_pos_one_hot_value[0])\n",
    "    board_full = np.array(np.reshape(board, [board.shape[0],49,1]))\n",
    "\n",
    "    return board_full, player_pos_one_hot_value, y[:,None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [state for game in games for state in game] \n",
    "board_full, player_pos, y = prepare_data_for_model(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Activation\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "player_pos_one_hot = Input(shape = [49, 2])\n",
    "board_state = Input(shape=[49,1])\n",
    "mask = board_state\n",
    "num_features = 3\n",
    "\n",
    "def ResNetLayerFun(x, num_features = 3, mask = None):\n",
    "    tmp = BatchNormalization()(x)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = BatchNormalization()(tmp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    return Add()([x,tmp])\n",
    "\n",
    "#tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "out = Concatenate()([board_state, player_pos_one_hot])\n",
    "out = ConvByMoveLayer(num_features, mask)(out)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = Activation('relu')(out)\n",
    "out = Concatenate()([out, player_pos_one_hot])\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation = 'relu')(out)\n",
    "out = Dense(1)(out)\n",
    "\n",
    "model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam',  loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit([player_pos, board_full],y, batch_size = 256, epochs=10, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get all those games where tree search actually completed\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "complete_states = [state for game in games for state in game if state['score'] == float('inf') or state['score'] == float('-inf')]\n",
    "print(len(complete_states))\n",
    "board_full_c, player_pos_c, y_c = prepare_data_for_model(complete_states,'score')\n",
    "y_c[y_c==float('inf')] = 1\n",
    "y_c[y_c==float('-inf')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(list(np.reshape(y_c,[-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Activation\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "player_pos_one_hot = Input(shape = [49, 2])\n",
    "board_state = Input(shape=[49,1])\n",
    "mask = board_state\n",
    "num_features = 3\n",
    "num_res_modules = 10\n",
    "\n",
    "def ResNetLayerFun(x, num_features = 3, mask = None):\n",
    "    tmp = BatchNormalization()(x)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    tmp = BatchNormalization()(tmp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = ConvByMoveLayer(num_features, mask)(tmp)\n",
    "    return Add()([x,tmp])\n",
    "\n",
    "#tmp1 = K.expand_dims(board_state, 2)# TODO: do this in Keras code\n",
    "out = Concatenate()([board_state, player_pos_one_hot])\n",
    "out = ConvByMoveLayer(num_features, mask)(out)\n",
    "for _ in range(num_res_modules):\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = ResNetLayerFun(out, num_features, mask)\n",
    "out = Activation('relu')(out)\n",
    "out = Concatenate()([out, player_pos_one_hot])\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation = 'relu')(out)\n",
    "out = Dense(2, activation = 'softmax')(out)\n",
    "\n",
    "deep_model = Model(inputs = [player_pos_one_hot, board_state], outputs = out)\n",
    "deep_model.summary()\n",
    "deep_model.compile(optimizer = 'adam',  loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "deep_model.fit([player_pos_c, board_full_c],to_categorical(y_c, num_classes=2), batch_size = 256, epochs=10, verbose =1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from copy import copy\n",
    "\n",
    "SimpleGame = namedtuple(\"Simple_game\", [\"moving_player_pos\",\"other_player_pos\", \"board\"])\n",
    "move_dict = generate_all_moves_by_index()\n",
    "\n",
    "def get_legal_moves(game):\n",
    "    if game.moving_player_pos is None:\n",
    "        return [m for m in range(49) if game.board[m] == 1]\n",
    "    else:\n",
    "        moves = move_dict[game.moving_player_pos]\n",
    "        return [m for m in moves if game.board[m] ==1 ]\n",
    "\n",
    "def apply_move(game, move):\n",
    "    if not move in get_legal_moves(game):\n",
    "        raise ValueError('Illegal move!')\n",
    "    new_board = copy(game.board)\n",
    "    new_board[move] = 0\n",
    "    other_pos = move\n",
    "    moving_pos = game.other_player_pos\n",
    "    return SimpleGame(moving_pos, other_pos, new_board)\n",
    "    \n",
    "board = np.ones(49)\n",
    "board.sum()\n",
    "my_pos = None\n",
    "other_pos = None\n",
    "game = SimpleGame(my_pos, other_pos, board)\n",
    "game1 = apply_move(game, 0, move_dict)\n",
    "game2 = apply_move(game1, 1, move_dict)\n",
    "game3 = apply_move(game2, 14, move_dict)\n",
    "print(game3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort all games by number of moves. \n",
    "\n",
    "\n",
    "states_by_num_moves = [[] for _ in range(49)]\n",
    "\n",
    "for state in states:\n",
    "    moves_made = 49 - state['game'].sum()\n",
    "    states_by_num_moves[int(moves_made)].append(state)\n",
    "    \n",
    "for n in range(49):\n",
    "    print(n,len(states_by_num_moves[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively populate all non-+-inf values in layer n from evaluating model in layer n+1, then include these into the fitting set\n",
    "# after each pass, refresh the values for earlier layers\n",
    "\n",
    "prepared_data = [None for _ in range(49)]\n",
    "for n in range(2,49):\n",
    "    prepared_data[n] = prepare_data_for_model( states_by_num_moves[n],'score') # board, player_pos, score\n",
    "    \n",
    "# TODO: is my position always first in those dumps???\n",
    "    \n",
    "def recursively_fill_scores(board, player_pos, scores, eval_fun):\n",
    "    new_scores = scores.copy()\n",
    "    new_scores[scores == float('inf')] =1 \n",
    "    new_scores[scores == float('-inf')] = 0\n",
    "    for n, score in enumerate(scores):\n",
    "        if score not in [float('inf'), float('-inf')]:\n",
    "            new_scores[n] = get_recursive_score(board[n], player_pos[n], eval_fun)\n",
    "            \n",
    "def get_recursive_score(board, player_pos, eval_fun):\n",
    "    this_game = SimpleGame(board, player_pos[0], player_pos[1])\n",
    "    moves = get_legal_moves(this_game)\n",
    "    vals = np.array([1 - eval_fun(apply_move(this_game, move)) for move in moves])\n",
    "    return vals.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
